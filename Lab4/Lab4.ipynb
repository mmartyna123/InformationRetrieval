{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 117,
      "id": "79e1864f",
      "metadata": {
        "id": "79e1864f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import cosine"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52d70d58",
      "metadata": {
        "id": "52d70d58"
      },
      "source": [
        "Today we will focus on finding similarities between documents. For this purpose, we will compare the content of these documents. The same techniques can be used for a query in a search engine. Then simply we can treat the query like another document, calculate similarities and return the most similar documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "id": "4286948a",
      "metadata": {
        "id": "4286948a"
      },
      "outputs": [],
      "source": [
        "documents = ['Machine Learning',\n",
        " 'Five Advanced Plots in Python - Matplotlib',\n",
        " 'How to Make your Computer Talk with Python',\n",
        " 'Anomaly Detection on Servo Drives',\n",
        " 'Key takeaways from Kaggle’s most recent time series competition - Ventilator Pressure Prediction',\n",
        " 'Animated Mathematical Analysis',\n",
        " 'How to Perform Speech Recognition with Python',\n",
        " 'Beyond The Semesters: E04',\n",
        " 'How to improve classification of e-commerce pages, incorporating multiple modalities',\n",
        " 'Time Series Forecasting with ThymeBoost',\n",
        " 'CHAPTER 2: Why I Chose Data Science!',\n",
        " 'Training Provably-Robust Neural Networks',\n",
        " 'Time Series Forecasting with ThymeBoost',\n",
        " 'How to improve classification of e-commerce pages, incorporating multiple modalities',\n",
        " '5 Cute Features of CatBoost',\n",
        " 'Variance Inflation Factor (VIF) and it’s relationship with multicollinearity&nbsp;.',\n",
        " 'Beyond The Semesters: E04',\n",
        " 'Efficient Digital Transformation - Particle Swarm Optimiser',\n",
        " 'MEASURE OF ASYMMETRY',\n",
        " 'What is linear regression? A quick cover with a tutorial',\n",
        " 'Correlation VS Covariance: The easy way',\n",
        " 'Are Recommender System harming us?',\n",
        " '1 Line of Python Code That Will Speed Up Your AI by Up to 6x',\n",
        " 'If You Are Serious About Data Science Job. You Must Know These 3 Things.',\n",
        " 'Recommender System With Machine Learning and Statistics',\n",
        " 'Bias detection and mitigation in IBM AutoAI',\n",
        " 'Data Engineering: Create your own Dataset',\n",
        " 'Graph Neural Networks and Generalizable Models in Neuroscience',\n",
        " 'Fastest Way of Deploying Your Machine Learning Models',\n",
        " 'A Novel Approach to Integrate Speech Recognition into Authentication Systems',\n",
        " '3 Lessons Learned in Teaching Machine Learning for Earth Observation Techniques',\n",
        " 'Vision Transformer in Galaxy Morphology Classification',\n",
        " 'Exploring Methods of Deep Reinforcement Learning with NLP Applications',\n",
        " '6 Essential Tips to Solve Data Science Projects',\n",
        " 'Data Science Interview Questions My Friends and I got asked recently (III)',\n",
        " 'Understanding Uber’s Generative Teaching Networks',\n",
        " 'How to achieve efficient large-batch training?',\n",
        " 'How Parallelization and Large Batch Size Improve the Performance of Deep Neural Networks.',\n",
        " 'Why You Need to Know the Inner Workings of Models',\n",
        " 'Let’s Build A Simple Object Classification Task I']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "id": "dfb57cc0",
      "metadata": {
        "id": "dfb57cc0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<40x150 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 204 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "CountVec = CountVectorizer(ngram_range=(1,1), stop_words='english')\n",
        "\n",
        "'''\n",
        "CountVectorizer converts a collection of docs into term-document matrix\n",
        "row -> document\n",
        "column -> term, word (ngram); here the ngram is (1,1) so just one word\n",
        "\n",
        "ngram_range=(1,1) -> singe words so unigrams\n",
        "ngram_range=(1,2) -> single words and pairs of words, so unigrams and bigrams\n",
        "ngram_range=(2,2) -> only bigrams\n",
        "GENERALLY:\n",
        "ngram_range=(n,m) -> n is the minimum number of words in a ngram and m is the maximum number of words in a ngram \n",
        "so if n==m then only ngrams of size n will be considered\n",
        "\n",
        "stopwords='english' -> removes common english words like 'the', 'is', 'and' etc.\n",
        "'''\n",
        "\n",
        "CountData = CountVec.fit_transform(documents)\n",
        "\n",
        "'''\n",
        "fit_transform(documents)\n",
        "fit -> learn vocabulary from the input i.e. docs; scans through them, identifies tokens (unique words) after the preprocessing\n",
        "(here preprocessing is removing stopwords) and assigns an index to each token\n",
        "transform -> convert the input docs into term-document matrix\n",
        "'''\n",
        "\n",
        "CountData"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b621173",
      "metadata": {
        "id": "0b621173"
      },
      "source": [
        "The very basic way of storing information about documents is word count. Simply for each document we store an information how many times each word appears. It can be stored in an array, however, it's not the best option since it will be filled mostly with 0s. That's why it's stored in a sparse matrix, but we can expand it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "id": "c4ef7983",
      "metadata": {
        "id": "c4ef7983",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>6x</th>\n",
              "      <th>achieve</th>\n",
              "      <th>advanced</th>\n",
              "      <th>ai</th>\n",
              "      <th>analysis</th>\n",
              "      <th>animated</th>\n",
              "      <th>anomaly</th>\n",
              "      <th>applications</th>\n",
              "      <th>approach</th>\n",
              "      <th>asked</th>\n",
              "      <th>...</th>\n",
              "      <th>tutorial</th>\n",
              "      <th>uber</th>\n",
              "      <th>understanding</th>\n",
              "      <th>variance</th>\n",
              "      <th>ventilator</th>\n",
              "      <th>vif</th>\n",
              "      <th>vision</th>\n",
              "      <th>vs</th>\n",
              "      <th>way</th>\n",
              "      <th>workings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Machine Learning</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Five Advanced Plots in Python - Matplotlib</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How to Make your Computer Talk with Python</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Anomaly Detection on Servo Drives</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Key takeaways from Kaggle’s most recent time series competition - Ventilator Pressure Prediction</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Animated Mathematical Analysis</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How to Perform Speech Recognition with Python</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Beyond The Semesters: E04</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How to improve classification of e-commerce pages, incorporating multiple modalities</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time Series Forecasting with ThymeBoost</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CHAPTER 2: Why I Chose Data Science!</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Training Provably-Robust Neural Networks</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time Series Forecasting with ThymeBoost</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How to improve classification of e-commerce pages, incorporating multiple modalities</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5 Cute Features of CatBoost</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variance Inflation Factor (VIF) and it’s relationship with multicollinearity&amp;nbsp;.</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Beyond The Semesters: E04</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Efficient Digital Transformation - Particle Swarm Optimiser</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MEASURE OF ASYMMETRY</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>What is linear regression? A quick cover with a tutorial</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Correlation VS Covariance: The easy way</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Are Recommender System harming us?</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1 Line of Python Code That Will Speed Up Your AI by Up to 6x</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>If You Are Serious About Data Science Job. You Must Know These 3 Things.</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recommender System With Machine Learning and Statistics</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bias detection and mitigation in IBM AutoAI</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Data Engineering: Create your own Dataset</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Graph Neural Networks and Generalizable Models in Neuroscience</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fastest Way of Deploying Your Machine Learning Models</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A Novel Approach to Integrate Speech Recognition into Authentication Systems</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3 Lessons Learned in Teaching Machine Learning for Earth Observation Techniques</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Vision Transformer in Galaxy Morphology Classification</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Exploring Methods of Deep Reinforcement Learning with NLP Applications</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6 Essential Tips to Solve Data Science Projects</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Data Science Interview Questions My Friends and I got asked recently (III)</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Understanding Uber’s Generative Teaching Networks</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How to achieve efficient large-batch training?</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How Parallelization and Large Batch Size Improve the Performance of Deep Neural Networks.</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Why You Need to Know the Inner Workings of Models</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Let’s Build A Simple Object Classification Task I</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40 rows × 150 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    6x  achieve  advanced  ai  \\\n",
              "Machine Learning                                     0        0         0   0   \n",
              "Five Advanced Plots in Python - Matplotlib           0        0         1   0   \n",
              "How to Make your Computer Talk with Python           0        0         0   0   \n",
              "Anomaly Detection on Servo Drives                    0        0         0   0   \n",
              "Key takeaways from Kaggle’s most recent time se...   0        0         0   0   \n",
              "Animated Mathematical Analysis                       0        0         0   0   \n",
              "How to Perform Speech Recognition with Python        0        0         0   0   \n",
              "Beyond The Semesters: E04                            0        0         0   0   \n",
              "How to improve classification of e-commerce pag...   0        0         0   0   \n",
              "Time Series Forecasting with ThymeBoost              0        0         0   0   \n",
              "CHAPTER 2: Why I Chose Data Science!                 0        0         0   0   \n",
              "Training Provably-Robust Neural Networks             0        0         0   0   \n",
              "Time Series Forecasting with ThymeBoost              0        0         0   0   \n",
              "How to improve classification of e-commerce pag...   0        0         0   0   \n",
              "5 Cute Features of CatBoost                          0        0         0   0   \n",
              "Variance Inflation Factor (VIF) and it’s relati...   0        0         0   0   \n",
              "Beyond The Semesters: E04                            0        0         0   0   \n",
              "Efficient Digital Transformation - Particle Swa...   0        0         0   0   \n",
              "MEASURE OF ASYMMETRY                                 0        0         0   0   \n",
              "What is linear regression? A quick cover with a...   0        0         0   0   \n",
              "Correlation VS Covariance: The easy way              0        0         0   0   \n",
              "Are Recommender System harming us?                   0        0         0   0   \n",
              "1 Line of Python Code That Will Speed Up Your A...   1        0         0   1   \n",
              "If You Are Serious About Data Science Job. You ...   0        0         0   0   \n",
              "Recommender System With Machine Learning and St...   0        0         0   0   \n",
              "Bias detection and mitigation in IBM AutoAI          0        0         0   0   \n",
              "Data Engineering: Create your own Dataset            0        0         0   0   \n",
              "Graph Neural Networks and Generalizable Models ...   0        0         0   0   \n",
              "Fastest Way of Deploying Your Machine Learning ...   0        0         0   0   \n",
              "A Novel Approach to Integrate Speech Recognitio...   0        0         0   0   \n",
              "3 Lessons Learned in Teaching Machine Learning ...   0        0         0   0   \n",
              "Vision Transformer in Galaxy Morphology Classif...   0        0         0   0   \n",
              "Exploring Methods of Deep Reinforcement Learnin...   0        0         0   0   \n",
              "6 Essential Tips to Solve Data Science Projects      0        0         0   0   \n",
              "Data Science Interview Questions My Friends and...   0        0         0   0   \n",
              "Understanding Uber’s Generative Teaching Networks    0        0         0   0   \n",
              "How to achieve efficient large-batch training?       0        1         0   0   \n",
              "How Parallelization and Large Batch Size Improv...   0        0         0   0   \n",
              "Why You Need to Know the Inner Workings of Models    0        0         0   0   \n",
              "Let’s Build A Simple Object Classification Task I    0        0         0   0   \n",
              "\n",
              "                                                    analysis  animated  \\\n",
              "Machine Learning                                           0         0   \n",
              "Five Advanced Plots in Python - Matplotlib                 0         0   \n",
              "How to Make your Computer Talk with Python                 0         0   \n",
              "Anomaly Detection on Servo Drives                          0         0   \n",
              "Key takeaways from Kaggle’s most recent time se...         0         0   \n",
              "Animated Mathematical Analysis                             1         1   \n",
              "How to Perform Speech Recognition with Python              0         0   \n",
              "Beyond The Semesters: E04                                  0         0   \n",
              "How to improve classification of e-commerce pag...         0         0   \n",
              "Time Series Forecasting with ThymeBoost                    0         0   \n",
              "CHAPTER 2: Why I Chose Data Science!                       0         0   \n",
              "Training Provably-Robust Neural Networks                   0         0   \n",
              "Time Series Forecasting with ThymeBoost                    0         0   \n",
              "How to improve classification of e-commerce pag...         0         0   \n",
              "5 Cute Features of CatBoost                                0         0   \n",
              "Variance Inflation Factor (VIF) and it’s relati...         0         0   \n",
              "Beyond The Semesters: E04                                  0         0   \n",
              "Efficient Digital Transformation - Particle Swa...         0         0   \n",
              "MEASURE OF ASYMMETRY                                       0         0   \n",
              "What is linear regression? A quick cover with a...         0         0   \n",
              "Correlation VS Covariance: The easy way                    0         0   \n",
              "Are Recommender System harming us?                         0         0   \n",
              "1 Line of Python Code That Will Speed Up Your A...         0         0   \n",
              "If You Are Serious About Data Science Job. You ...         0         0   \n",
              "Recommender System With Machine Learning and St...         0         0   \n",
              "Bias detection and mitigation in IBM AutoAI                0         0   \n",
              "Data Engineering: Create your own Dataset                  0         0   \n",
              "Graph Neural Networks and Generalizable Models ...         0         0   \n",
              "Fastest Way of Deploying Your Machine Learning ...         0         0   \n",
              "A Novel Approach to Integrate Speech Recognitio...         0         0   \n",
              "3 Lessons Learned in Teaching Machine Learning ...         0         0   \n",
              "Vision Transformer in Galaxy Morphology Classif...         0         0   \n",
              "Exploring Methods of Deep Reinforcement Learnin...         0         0   \n",
              "6 Essential Tips to Solve Data Science Projects            0         0   \n",
              "Data Science Interview Questions My Friends and...         0         0   \n",
              "Understanding Uber’s Generative Teaching Networks          0         0   \n",
              "How to achieve efficient large-batch training?             0         0   \n",
              "How Parallelization and Large Batch Size Improv...         0         0   \n",
              "Why You Need to Know the Inner Workings of Models          0         0   \n",
              "Let’s Build A Simple Object Classification Task I          0         0   \n",
              "\n",
              "                                                    anomaly  applications  \\\n",
              "Machine Learning                                          0             0   \n",
              "Five Advanced Plots in Python - Matplotlib                0             0   \n",
              "How to Make your Computer Talk with Python                0             0   \n",
              "Anomaly Detection on Servo Drives                         1             0   \n",
              "Key takeaways from Kaggle’s most recent time se...        0             0   \n",
              "Animated Mathematical Analysis                            0             0   \n",
              "How to Perform Speech Recognition with Python             0             0   \n",
              "Beyond The Semesters: E04                                 0             0   \n",
              "How to improve classification of e-commerce pag...        0             0   \n",
              "Time Series Forecasting with ThymeBoost                   0             0   \n",
              "CHAPTER 2: Why I Chose Data Science!                      0             0   \n",
              "Training Provably-Robust Neural Networks                  0             0   \n",
              "Time Series Forecasting with ThymeBoost                   0             0   \n",
              "How to improve classification of e-commerce pag...        0             0   \n",
              "5 Cute Features of CatBoost                               0             0   \n",
              "Variance Inflation Factor (VIF) and it’s relati...        0             0   \n",
              "Beyond The Semesters: E04                                 0             0   \n",
              "Efficient Digital Transformation - Particle Swa...        0             0   \n",
              "MEASURE OF ASYMMETRY                                      0             0   \n",
              "What is linear regression? A quick cover with a...        0             0   \n",
              "Correlation VS Covariance: The easy way                   0             0   \n",
              "Are Recommender System harming us?                        0             0   \n",
              "1 Line of Python Code That Will Speed Up Your A...        0             0   \n",
              "If You Are Serious About Data Science Job. You ...        0             0   \n",
              "Recommender System With Machine Learning and St...        0             0   \n",
              "Bias detection and mitigation in IBM AutoAI               0             0   \n",
              "Data Engineering: Create your own Dataset                 0             0   \n",
              "Graph Neural Networks and Generalizable Models ...        0             0   \n",
              "Fastest Way of Deploying Your Machine Learning ...        0             0   \n",
              "A Novel Approach to Integrate Speech Recognitio...        0             0   \n",
              "3 Lessons Learned in Teaching Machine Learning ...        0             0   \n",
              "Vision Transformer in Galaxy Morphology Classif...        0             0   \n",
              "Exploring Methods of Deep Reinforcement Learnin...        0             1   \n",
              "6 Essential Tips to Solve Data Science Projects           0             0   \n",
              "Data Science Interview Questions My Friends and...        0             0   \n",
              "Understanding Uber’s Generative Teaching Networks         0             0   \n",
              "How to achieve efficient large-batch training?            0             0   \n",
              "How Parallelization and Large Batch Size Improv...        0             0   \n",
              "Why You Need to Know the Inner Workings of Models         0             0   \n",
              "Let’s Build A Simple Object Classification Task I         0             0   \n",
              "\n",
              "                                                    approach  asked  ...  \\\n",
              "Machine Learning                                           0      0  ...   \n",
              "Five Advanced Plots in Python - Matplotlib                 0      0  ...   \n",
              "How to Make your Computer Talk with Python                 0      0  ...   \n",
              "Anomaly Detection on Servo Drives                          0      0  ...   \n",
              "Key takeaways from Kaggle’s most recent time se...         0      0  ...   \n",
              "Animated Mathematical Analysis                             0      0  ...   \n",
              "How to Perform Speech Recognition with Python              0      0  ...   \n",
              "Beyond The Semesters: E04                                  0      0  ...   \n",
              "How to improve classification of e-commerce pag...         0      0  ...   \n",
              "Time Series Forecasting with ThymeBoost                    0      0  ...   \n",
              "CHAPTER 2: Why I Chose Data Science!                       0      0  ...   \n",
              "Training Provably-Robust Neural Networks                   0      0  ...   \n",
              "Time Series Forecasting with ThymeBoost                    0      0  ...   \n",
              "How to improve classification of e-commerce pag...         0      0  ...   \n",
              "5 Cute Features of CatBoost                                0      0  ...   \n",
              "Variance Inflation Factor (VIF) and it’s relati...         0      0  ...   \n",
              "Beyond The Semesters: E04                                  0      0  ...   \n",
              "Efficient Digital Transformation - Particle Swa...         0      0  ...   \n",
              "MEASURE OF ASYMMETRY                                       0      0  ...   \n",
              "What is linear regression? A quick cover with a...         0      0  ...   \n",
              "Correlation VS Covariance: The easy way                    0      0  ...   \n",
              "Are Recommender System harming us?                         0      0  ...   \n",
              "1 Line of Python Code That Will Speed Up Your A...         0      0  ...   \n",
              "If You Are Serious About Data Science Job. You ...         0      0  ...   \n",
              "Recommender System With Machine Learning and St...         0      0  ...   \n",
              "Bias detection and mitigation in IBM AutoAI                0      0  ...   \n",
              "Data Engineering: Create your own Dataset                  0      0  ...   \n",
              "Graph Neural Networks and Generalizable Models ...         0      0  ...   \n",
              "Fastest Way of Deploying Your Machine Learning ...         0      0  ...   \n",
              "A Novel Approach to Integrate Speech Recognitio...         1      0  ...   \n",
              "3 Lessons Learned in Teaching Machine Learning ...         0      0  ...   \n",
              "Vision Transformer in Galaxy Morphology Classif...         0      0  ...   \n",
              "Exploring Methods of Deep Reinforcement Learnin...         0      0  ...   \n",
              "6 Essential Tips to Solve Data Science Projects            0      0  ...   \n",
              "Data Science Interview Questions My Friends and...         0      1  ...   \n",
              "Understanding Uber’s Generative Teaching Networks          0      0  ...   \n",
              "How to achieve efficient large-batch training?             0      0  ...   \n",
              "How Parallelization and Large Batch Size Improv...         0      0  ...   \n",
              "Why You Need to Know the Inner Workings of Models          0      0  ...   \n",
              "Let’s Build A Simple Object Classification Task I          0      0  ...   \n",
              "\n",
              "                                                    tutorial  uber  \\\n",
              "Machine Learning                                           0     0   \n",
              "Five Advanced Plots in Python - Matplotlib                 0     0   \n",
              "How to Make your Computer Talk with Python                 0     0   \n",
              "Anomaly Detection on Servo Drives                          0     0   \n",
              "Key takeaways from Kaggle’s most recent time se...         0     0   \n",
              "Animated Mathematical Analysis                             0     0   \n",
              "How to Perform Speech Recognition with Python              0     0   \n",
              "Beyond The Semesters: E04                                  0     0   \n",
              "How to improve classification of e-commerce pag...         0     0   \n",
              "Time Series Forecasting with ThymeBoost                    0     0   \n",
              "CHAPTER 2: Why I Chose Data Science!                       0     0   \n",
              "Training Provably-Robust Neural Networks                   0     0   \n",
              "Time Series Forecasting with ThymeBoost                    0     0   \n",
              "How to improve classification of e-commerce pag...         0     0   \n",
              "5 Cute Features of CatBoost                                0     0   \n",
              "Variance Inflation Factor (VIF) and it’s relati...         0     0   \n",
              "Beyond The Semesters: E04                                  0     0   \n",
              "Efficient Digital Transformation - Particle Swa...         0     0   \n",
              "MEASURE OF ASYMMETRY                                       0     0   \n",
              "What is linear regression? A quick cover with a...         1     0   \n",
              "Correlation VS Covariance: The easy way                    0     0   \n",
              "Are Recommender System harming us?                         0     0   \n",
              "1 Line of Python Code That Will Speed Up Your A...         0     0   \n",
              "If You Are Serious About Data Science Job. You ...         0     0   \n",
              "Recommender System With Machine Learning and St...         0     0   \n",
              "Bias detection and mitigation in IBM AutoAI                0     0   \n",
              "Data Engineering: Create your own Dataset                  0     0   \n",
              "Graph Neural Networks and Generalizable Models ...         0     0   \n",
              "Fastest Way of Deploying Your Machine Learning ...         0     0   \n",
              "A Novel Approach to Integrate Speech Recognitio...         0     0   \n",
              "3 Lessons Learned in Teaching Machine Learning ...         0     0   \n",
              "Vision Transformer in Galaxy Morphology Classif...         0     0   \n",
              "Exploring Methods of Deep Reinforcement Learnin...         0     0   \n",
              "6 Essential Tips to Solve Data Science Projects            0     0   \n",
              "Data Science Interview Questions My Friends and...         0     0   \n",
              "Understanding Uber’s Generative Teaching Networks          0     1   \n",
              "How to achieve efficient large-batch training?             0     0   \n",
              "How Parallelization and Large Batch Size Improv...         0     0   \n",
              "Why You Need to Know the Inner Workings of Models          0     0   \n",
              "Let’s Build A Simple Object Classification Task I          0     0   \n",
              "\n",
              "                                                    understanding  variance  \\\n",
              "Machine Learning                                                0         0   \n",
              "Five Advanced Plots in Python - Matplotlib                      0         0   \n",
              "How to Make your Computer Talk with Python                      0         0   \n",
              "Anomaly Detection on Servo Drives                               0         0   \n",
              "Key takeaways from Kaggle’s most recent time se...              0         0   \n",
              "Animated Mathematical Analysis                                  0         0   \n",
              "How to Perform Speech Recognition with Python                   0         0   \n",
              "Beyond The Semesters: E04                                       0         0   \n",
              "How to improve classification of e-commerce pag...              0         0   \n",
              "Time Series Forecasting with ThymeBoost                         0         0   \n",
              "CHAPTER 2: Why I Chose Data Science!                            0         0   \n",
              "Training Provably-Robust Neural Networks                        0         0   \n",
              "Time Series Forecasting with ThymeBoost                         0         0   \n",
              "How to improve classification of e-commerce pag...              0         0   \n",
              "5 Cute Features of CatBoost                                     0         0   \n",
              "Variance Inflation Factor (VIF) and it’s relati...              0         1   \n",
              "Beyond The Semesters: E04                                       0         0   \n",
              "Efficient Digital Transformation - Particle Swa...              0         0   \n",
              "MEASURE OF ASYMMETRY                                            0         0   \n",
              "What is linear regression? A quick cover with a...              0         0   \n",
              "Correlation VS Covariance: The easy way                         0         0   \n",
              "Are Recommender System harming us?                              0         0   \n",
              "1 Line of Python Code That Will Speed Up Your A...              0         0   \n",
              "If You Are Serious About Data Science Job. You ...              0         0   \n",
              "Recommender System With Machine Learning and St...              0         0   \n",
              "Bias detection and mitigation in IBM AutoAI                     0         0   \n",
              "Data Engineering: Create your own Dataset                       0         0   \n",
              "Graph Neural Networks and Generalizable Models ...              0         0   \n",
              "Fastest Way of Deploying Your Machine Learning ...              0         0   \n",
              "A Novel Approach to Integrate Speech Recognitio...              0         0   \n",
              "3 Lessons Learned in Teaching Machine Learning ...              0         0   \n",
              "Vision Transformer in Galaxy Morphology Classif...              0         0   \n",
              "Exploring Methods of Deep Reinforcement Learnin...              0         0   \n",
              "6 Essential Tips to Solve Data Science Projects                 0         0   \n",
              "Data Science Interview Questions My Friends and...              0         0   \n",
              "Understanding Uber’s Generative Teaching Networks               1         0   \n",
              "How to achieve efficient large-batch training?                  0         0   \n",
              "How Parallelization and Large Batch Size Improv...              0         0   \n",
              "Why You Need to Know the Inner Workings of Models               0         0   \n",
              "Let’s Build A Simple Object Classification Task I               0         0   \n",
              "\n",
              "                                                    ventilator  vif  vision  \\\n",
              "Machine Learning                                             0    0       0   \n",
              "Five Advanced Plots in Python - Matplotlib                   0    0       0   \n",
              "How to Make your Computer Talk with Python                   0    0       0   \n",
              "Anomaly Detection on Servo Drives                            0    0       0   \n",
              "Key takeaways from Kaggle’s most recent time se...           1    0       0   \n",
              "Animated Mathematical Analysis                               0    0       0   \n",
              "How to Perform Speech Recognition with Python                0    0       0   \n",
              "Beyond The Semesters: E04                                    0    0       0   \n",
              "How to improve classification of e-commerce pag...           0    0       0   \n",
              "Time Series Forecasting with ThymeBoost                      0    0       0   \n",
              "CHAPTER 2: Why I Chose Data Science!                         0    0       0   \n",
              "Training Provably-Robust Neural Networks                     0    0       0   \n",
              "Time Series Forecasting with ThymeBoost                      0    0       0   \n",
              "How to improve classification of e-commerce pag...           0    0       0   \n",
              "5 Cute Features of CatBoost                                  0    0       0   \n",
              "Variance Inflation Factor (VIF) and it’s relati...           0    1       0   \n",
              "Beyond The Semesters: E04                                    0    0       0   \n",
              "Efficient Digital Transformation - Particle Swa...           0    0       0   \n",
              "MEASURE OF ASYMMETRY                                         0    0       0   \n",
              "What is linear regression? A quick cover with a...           0    0       0   \n",
              "Correlation VS Covariance: The easy way                      0    0       0   \n",
              "Are Recommender System harming us?                           0    0       0   \n",
              "1 Line of Python Code That Will Speed Up Your A...           0    0       0   \n",
              "If You Are Serious About Data Science Job. You ...           0    0       0   \n",
              "Recommender System With Machine Learning and St...           0    0       0   \n",
              "Bias detection and mitigation in IBM AutoAI                  0    0       0   \n",
              "Data Engineering: Create your own Dataset                    0    0       0   \n",
              "Graph Neural Networks and Generalizable Models ...           0    0       0   \n",
              "Fastest Way of Deploying Your Machine Learning ...           0    0       0   \n",
              "A Novel Approach to Integrate Speech Recognitio...           0    0       0   \n",
              "3 Lessons Learned in Teaching Machine Learning ...           0    0       0   \n",
              "Vision Transformer in Galaxy Morphology Classif...           0    0       1   \n",
              "Exploring Methods of Deep Reinforcement Learnin...           0    0       0   \n",
              "6 Essential Tips to Solve Data Science Projects              0    0       0   \n",
              "Data Science Interview Questions My Friends and...           0    0       0   \n",
              "Understanding Uber’s Generative Teaching Networks            0    0       0   \n",
              "How to achieve efficient large-batch training?               0    0       0   \n",
              "How Parallelization and Large Batch Size Improv...           0    0       0   \n",
              "Why You Need to Know the Inner Workings of Models            0    0       0   \n",
              "Let’s Build A Simple Object Classification Task I            0    0       0   \n",
              "\n",
              "                                                    vs  way  workings  \n",
              "Machine Learning                                     0    0         0  \n",
              "Five Advanced Plots in Python - Matplotlib           0    0         0  \n",
              "How to Make your Computer Talk with Python           0    0         0  \n",
              "Anomaly Detection on Servo Drives                    0    0         0  \n",
              "Key takeaways from Kaggle’s most recent time se...   0    0         0  \n",
              "Animated Mathematical Analysis                       0    0         0  \n",
              "How to Perform Speech Recognition with Python        0    0         0  \n",
              "Beyond The Semesters: E04                            0    0         0  \n",
              "How to improve classification of e-commerce pag...   0    0         0  \n",
              "Time Series Forecasting with ThymeBoost              0    0         0  \n",
              "CHAPTER 2: Why I Chose Data Science!                 0    0         0  \n",
              "Training Provably-Robust Neural Networks             0    0         0  \n",
              "Time Series Forecasting with ThymeBoost              0    0         0  \n",
              "How to improve classification of e-commerce pag...   0    0         0  \n",
              "5 Cute Features of CatBoost                          0    0         0  \n",
              "Variance Inflation Factor (VIF) and it’s relati...   0    0         0  \n",
              "Beyond The Semesters: E04                            0    0         0  \n",
              "Efficient Digital Transformation - Particle Swa...   0    0         0  \n",
              "MEASURE OF ASYMMETRY                                 0    0         0  \n",
              "What is linear regression? A quick cover with a...   0    0         0  \n",
              "Correlation VS Covariance: The easy way              1    1         0  \n",
              "Are Recommender System harming us?                   0    0         0  \n",
              "1 Line of Python Code That Will Speed Up Your A...   0    0         0  \n",
              "If You Are Serious About Data Science Job. You ...   0    0         0  \n",
              "Recommender System With Machine Learning and St...   0    0         0  \n",
              "Bias detection and mitigation in IBM AutoAI          0    0         0  \n",
              "Data Engineering: Create your own Dataset            0    0         0  \n",
              "Graph Neural Networks and Generalizable Models ...   0    0         0  \n",
              "Fastest Way of Deploying Your Machine Learning ...   0    1         0  \n",
              "A Novel Approach to Integrate Speech Recognitio...   0    0         0  \n",
              "3 Lessons Learned in Teaching Machine Learning ...   0    0         0  \n",
              "Vision Transformer in Galaxy Morphology Classif...   0    0         0  \n",
              "Exploring Methods of Deep Reinforcement Learnin...   0    0         0  \n",
              "6 Essential Tips to Solve Data Science Projects      0    0         0  \n",
              "Data Science Interview Questions My Friends and...   0    0         0  \n",
              "Understanding Uber’s Generative Teaching Networks    0    0         0  \n",
              "How to achieve efficient large-batch training?       0    0         0  \n",
              "How Parallelization and Large Batch Size Improv...   0    0         0  \n",
              "Why You Need to Know the Inner Workings of Models    0    0         1  \n",
              "Let’s Build A Simple Object Classification Task I    0    0         0  \n",
              "\n",
              "[40 rows x 150 columns]"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df=pd.DataFrame(CountData.toarray(), columns=CountVec.get_feature_names_out(), index=documents)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e5f4c41",
      "metadata": {
        "id": "2e5f4c41"
      },
      "source": [
        "## Task 1\n",
        "We can reduce the size of an array, get rid of unnecesary words, and improve the quality of comparison by firstly preprocessing the docuemnts.\n",
        "Check array size after stemming/lemmatization and without stop words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "id": "6f4a8885",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\mmart\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\mmart\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\mmart\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "id": "f87bab12",
      "metadata": {
        "id": "f87bab12"
      },
      "outputs": [],
      "source": [
        "porter = PorterStemmer()\n",
        "lancaster = LancasterStemmer()\n",
        "wordNet = WordNetLemmatizer()\n",
        "stopWords = set(stopwords.words('english'))\n",
        "\n",
        "# def wordPunctTokens(doc):\n",
        "#     return wordpunct_tokenize(doc)\n",
        "\n",
        "\n",
        "# def wordTokens(doc):\n",
        "#     return word_tokenize(doc)\n",
        "\n",
        "# def porterStem(tokens):\n",
        "#     return [porter.stem(token) for token in tokens]\n",
        "\n",
        "\n",
        "def preprocess_doc(doc, tokenizer=word_tokenize ,stemmer=None, lemmatizer=None, use_lemmatizer=False):\n",
        "    tokens = tokenizer(doc.lower()) # tokenize the doc and convert to lowercase\n",
        "    terms = [word for word in tokens if word.isalpha() and word not in stopWords] # remove stopwords and non-alphabetic words\n",
        "    if use_lemmatizer and lemmatizer:\n",
        "        processed = [lemmatizer.lemmatize(word) for word in terms]\n",
        "    elif stemmer:\n",
        "        processed = [stemmer.stem(word) for word in terms] # stem the words \n",
        "    else:\n",
        "        processed = terms\n",
        "    \n",
        "    return ' '. join(processed)   \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "id": "f6cbea00",
      "metadata": {},
      "outputs": [],
      "source": [
        "processed_docs_porter = [preprocess_doc(doc, stemmer=porter) for doc in documents]\n",
        "processed_docs_porter_wordpunct = [preprocess_doc(doc, tokenizer=wordpunct_tokenize, stemmer=porter) for doc in documents]\n",
        "\n",
        "processed_docs_lancaster = [preprocess_doc(doc, stemmer=lancaster) for doc in documents]\n",
        "processed_docs_lancaster_wordpunct = [preprocess_doc(doc, tokenizer=wordpunct_tokenize, stemmer=lancaster) for doc in documents]\n",
        "\n",
        "processed_docs_wordnet = [preprocess_doc(doc, lemmatizer=wordNet, use_lemmatizer=True) for doc in documents]\n",
        "processed_docs_wordnet_wordpunct = [preprocess_doc(doc, tokenizer=wordpunct_tokenize, lemmatizer=wordNet, use_lemmatizer=True) for doc in documents]\n",
        "\n",
        "\n",
        "processed_docs = {\n",
        "    \"Porter (word_tokenize)\": processed_docs_porter,\n",
        "    \"Porter (wordpunct_tokenize)\": processed_docs_porter_wordpunct,\n",
        "    \"Lancaster (word_tokenize)\": processed_docs_lancaster,\n",
        "    \"Lancaster (wordpunct_tokenize)\": processed_docs_lancaster_wordpunct,\n",
        "    \"WordNet Lemmatizer (word_tokenize)\": processed_docs_wordnet,\n",
        "    \"WordNet Lemmatizer (wordpunct_tokenize)\": processed_docs_wordnet_wordpunct,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "id": "5643c3cc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Porter (word_tokenize): Number of terms = 141\n",
            "Porter (wordpunct_tokenize): Number of terms = 144\n",
            "Lancaster (word_tokenize): Number of terms = 138\n",
            "Lancaster (wordpunct_tokenize): Number of terms = 141\n",
            "WordNet Lemmatizer (word_tokenize): Number of terms = 143\n",
            "WordNet Lemmatizer (wordpunct_tokenize): Number of terms = 146\n"
          ]
        }
      ],
      "source": [
        "for name, processed_doc in processed_docs.items():\n",
        "    CountVec = CountVectorizer(ngram_range=(1,1), stop_words='english')\n",
        "    CountData = CountVec.fit_transform(processed_doc)\n",
        "    num_columns = len(CountVec.get_feature_names_out())\n",
        "    print(f\"{name}: Number of terms = {num_columns}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b300849b",
      "metadata": {
        "id": "b300849b"
      },
      "source": [
        "## Task 2\n",
        "\n",
        "Easy technique to compare two documents is a jaccard similarity.\n",
        "$J={\\frac {|A\\cap B|}{|A\\cup B|}}.$\n",
        "\n",
        "Implement Jaccard similarity, and function finding closest document to a provided query. Test different queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "id": "a82f68b4",
      "metadata": {
        "id": "a82f68b4"
      },
      "outputs": [],
      "source": [
        "def jaccard(d1, d2):\n",
        "    set1 = set(d1.split())\n",
        "    set2 = set(d2.split())\n",
        "    intersection = set1.intersection(set2)\n",
        "    union = set1.union(set2)\n",
        "    return len(intersection) / len(union)\n",
        "\n",
        "def closest(query, documents):\n",
        "    processed_query = preprocess_doc(query, stemmer=porter)\n",
        "    processed_docs = [preprocess_doc(doc, stemmer=porter) for doc in documents]\n",
        "    similarities = [jaccard(processed_query, doc) for doc in processed_docs]\n",
        "    max_index = similarities.index(max(similarities))\n",
        "    return documents[max_index], max(similarities)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83d10b06",
      "metadata": {
        "id": "83d10b06"
      },
      "source": [
        "<a href=\"https://ibb.co/k4rRpf9\"><img src=\"https://i.ibb.co/GW1KXLt/ir4.jpg\" alt=\"ir4\" border=\"0\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "id": "c9226555",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Machine Learning',\n",
              " 'Five Advanced Plots in Python - Matplotlib',\n",
              " 'How to Make your Computer Talk with Python',\n",
              " 'Anomaly Detection on Servo Drives',\n",
              " 'Key takeaways from Kaggle’s most recent time series competition - Ventilator Pressure Prediction',\n",
              " 'Animated Mathematical Analysis',\n",
              " 'How to Perform Speech Recognition with Python',\n",
              " 'Beyond The Semesters: E04',\n",
              " 'How to improve classification of e-commerce pages, incorporating multiple modalities',\n",
              " 'Time Series Forecasting with ThymeBoost',\n",
              " 'CHAPTER 2: Why I Chose Data Science!',\n",
              " 'Training Provably-Robust Neural Networks',\n",
              " 'Time Series Forecasting with ThymeBoost',\n",
              " 'How to improve classification of e-commerce pages, incorporating multiple modalities',\n",
              " '5 Cute Features of CatBoost',\n",
              " 'Variance Inflation Factor (VIF) and it’s relationship with multicollinearity&nbsp;.',\n",
              " 'Beyond The Semesters: E04',\n",
              " 'Efficient Digital Transformation - Particle Swarm Optimiser',\n",
              " 'MEASURE OF ASYMMETRY',\n",
              " 'What is linear regression? A quick cover with a tutorial',\n",
              " 'Correlation VS Covariance: The easy way',\n",
              " 'Are Recommender System harming us?',\n",
              " '1 Line of Python Code That Will Speed Up Your AI by Up to 6x',\n",
              " 'If You Are Serious About Data Science Job. You Must Know These 3 Things.',\n",
              " 'Recommender System With Machine Learning and Statistics',\n",
              " 'Bias detection and mitigation in IBM AutoAI',\n",
              " 'Data Engineering: Create your own Dataset',\n",
              " 'Graph Neural Networks and Generalizable Models in Neuroscience',\n",
              " 'Fastest Way of Deploying Your Machine Learning Models',\n",
              " 'A Novel Approach to Integrate Speech Recognition into Authentication Systems',\n",
              " '3 Lessons Learned in Teaching Machine Learning for Earth Observation Techniques',\n",
              " 'Vision Transformer in Galaxy Morphology Classification',\n",
              " 'Exploring Methods of Deep Reinforcement Learning with NLP Applications',\n",
              " '6 Essential Tips to Solve Data Science Projects',\n",
              " 'Data Science Interview Questions My Friends and I got asked recently (III)',\n",
              " 'Understanding Uber’s Generative Teaching Networks',\n",
              " 'How to achieve efficient large-batch training?',\n",
              " 'How Parallelization and Large Batch Size Improve the Performance of Deep Neural Networks.',\n",
              " 'Why You Need to Know the Inner Workings of Models',\n",
              " 'Let’s Build A Simple Object Classification Task I']"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "id": "e64780c4",
      "metadata": {
        "id": "e64780c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: python\n",
            "Closest document: How to Make your Computer Talk with Python\n",
            "Jaccard Similarity: 0.25\n",
            "\n",
            "Query: plot neural network\n",
            "Closest document: Training Provably-Robust Neural Networks\n",
            "Jaccard Similarity: 0.50\n",
            "\n",
            "Query: plot neural networks\n",
            "Closest document: Training Provably-Robust Neural Networks\n",
            "Jaccard Similarity: 0.50\n",
            "\n",
            "Query: ploting neural networks\n",
            "Closest document: Training Provably-Robust Neural Networks\n",
            "Jaccard Similarity: 0.50\n",
            "\n",
            "Query: data science\n",
            "Closest document: CHAPTER 2: Why I Chose Data Science!\n",
            "Jaccard Similarity: 0.50\n",
            "\n",
            "Query: 5 Cute Features of CatBoost\n",
            "Closest document: 5 Cute Features of CatBoost\n",
            "Jaccard Similarity: 1.00\n",
            "\n"
          ]
        }
      ],
      "source": [
        "queries = [\n",
        "    \"python\",\n",
        "    \"plot neural network\",\n",
        "    \"plot neural networks\",\n",
        "    \"ploting neural networks\",\n",
        "    \"data science\",\n",
        "    \"5 Cute Features of CatBoost\"\n",
        "]\n",
        "for q in queries:\n",
        "    print(f\"Query: {q}\")\n",
        "    # print(closest(q, df))\n",
        "\n",
        "    closest_doc, similarity = closest(q, documents)\n",
        "    print(f\"Closest document: {closest_doc}\")\n",
        "    print(f\"Jaccard Similarity: {similarity:.2f}\\n\")\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae7a42c0",
      "metadata": {
        "id": "ae7a42c0"
      },
      "source": [
        "## Task 3\n",
        "\n",
        "TFIDF (term frequency–inverse document frequency) is a much better approach. The tf–idf value increases proportionally to the number of times a word appears in the document and is offset by the number of documents in the corpus that contain the word, which helps to adjust for the fact that some words appear more frequently in general.\n",
        "\n",
        "This approach consists of 2 steps:\n",
        "TF (term frequency) -  $tf(t,d)$, is the relative frequency of term $t$ within document $d$, can be expressed e.g. as a word count divided by number of terms in a given document or by the maximum term count in a given document.\n",
        "\n",
        "IDF (inverse document frequency) - is a measure of how much information the word provides. If a word appears in every document it does not provide much information, but if it just appears in two documents then its impact on similiarity between these two documents is higher. The standard approach to compute this value is logarithm of number of documents divided by number of documents containing a given term $IDF(t) = log(\\frac{N}{n_t})$\n",
        "\n",
        "TFIDF is then just TF multiplied by IDF\n",
        "\n",
        "\n",
        "Implement tf idf, compare it with sklearn TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "id": "c4728b41",
      "metadata": {
        "id": "c4728b41"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>6x</th>\n",
              "      <th>about</th>\n",
              "      <th>achieve</th>\n",
              "      <th>advanced</th>\n",
              "      <th>ai</th>\n",
              "      <th>analysis</th>\n",
              "      <th>and</th>\n",
              "      <th>animated</th>\n",
              "      <th>anomaly</th>\n",
              "      <th>applications</th>\n",
              "      <th>...</th>\n",
              "      <th>vision</th>\n",
              "      <th>vs</th>\n",
              "      <th>way</th>\n",
              "      <th>what</th>\n",
              "      <th>why</th>\n",
              "      <th>will</th>\n",
              "      <th>with</th>\n",
              "      <th>workings</th>\n",
              "      <th>you</th>\n",
              "      <th>your</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Machine Learning</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Five Advanced Plots in Python - Matplotlib</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.450495</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How to Make your Computer Talk with Python</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.249731</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.316067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Anomaly Detection on Servo Drives</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.459985</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Key takeaways from Kaggle’s most recent time series competition - Ventilator Pressure Prediction</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Animated Mathematical Analysis</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.57735</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.57735</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How to Perform Speech Recognition with Python</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.280999</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Beyond The Semesters: E04</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How to improve classification of e-commerce pages, incorporating multiple modalities</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time Series Forecasting with ThymeBoost</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.324860</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CHAPTER 2: Why I Chose Data Science!</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.445826</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Training Provably-Robust Neural Networks</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time Series Forecasting with ThymeBoost</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.324860</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How to improve classification of e-commerce pages, incorporating multiple modalities</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5 Cute Features of CatBoost</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variance Inflation Factor (VIF) and it’s relationship with multicollinearity&amp;nbsp;.</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.209580</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.188769</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Beyond The Semesters: E04</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Efficient Digital Transformation - Particle Swarm Optimiser</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MEASURE OF ASYMMETRY</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>What is linear regression? A quick cover with a tutorial</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.369871</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.205839</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Correlation VS Covariance: The easy way</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.440331</td>\n",
              "      <td>0.375238</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Are Recommender System harming us?</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1 Line of Python Code That Will Speed Up Your AI by Up to 6x</th>\n",
              "      <td>0.271593</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.271593</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.271593</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.191295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>If You Are Serious About Data Science Job. You Must Know These 3 Things.</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.285312</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.486269</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recommender System With Machine Learning and Statistics</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.306218</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.275811</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bias detection and mitigation in IBM AutoAI</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.262525</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Data Engineering: Create your own Dataset</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.317303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Graph Neural Networks and Generalizable Models in Neuroscience</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.263898</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fastest Way of Deploying Your Machine Learning Models</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.380404</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.314414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A Novel Approach to Integrate Speech Recognition into Authentication Systems</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3 Lessons Learned in Teaching Machine Learning for Earth Observation Techniques</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Vision Transformer in Galaxy Morphology Classification</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.450495</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Exploring Methods of Deep Reinforcement Learning with NLP Applications</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.384911</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.214209</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6 Essential Tips to Solve Data Science Projects</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Data Science Interview Questions My Friends and I got asked recently (III)</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.202508</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Understanding Uber’s Generative Teaching Networks</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How to achieve efficient large-batch training?</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.467835</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>How Parallelization and Large Batch Size Improve the Performance of Deep Neural Networks.</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.214150</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Why You Need to Know the Inner Workings of Models</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.327735</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.384588</td>\n",
              "      <td>0.327735</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Let’s Build A Simple Object Classification Task I</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40 rows × 184 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                          6x     about  \\\n",
              "Machine Learning                                    0.000000  0.000000   \n",
              "Five Advanced Plots in Python - Matplotlib          0.000000  0.000000   \n",
              "How to Make your Computer Talk with Python          0.000000  0.000000   \n",
              "Anomaly Detection on Servo Drives                   0.000000  0.000000   \n",
              "Key takeaways from Kaggle’s most recent time se...  0.000000  0.000000   \n",
              "Animated Mathematical Analysis                      0.000000  0.000000   \n",
              "How to Perform Speech Recognition with Python       0.000000  0.000000   \n",
              "Beyond The Semesters: E04                           0.000000  0.000000   \n",
              "How to improve classification of e-commerce pag...  0.000000  0.000000   \n",
              "Time Series Forecasting with ThymeBoost             0.000000  0.000000   \n",
              "CHAPTER 2: Why I Chose Data Science!                0.000000  0.000000   \n",
              "Training Provably-Robust Neural Networks            0.000000  0.000000   \n",
              "Time Series Forecasting with ThymeBoost             0.000000  0.000000   \n",
              "How to improve classification of e-commerce pag...  0.000000  0.000000   \n",
              "5 Cute Features of CatBoost                         0.000000  0.000000   \n",
              "Variance Inflation Factor (VIF) and it’s relati...  0.000000  0.000000   \n",
              "Beyond The Semesters: E04                           0.000000  0.000000   \n",
              "Efficient Digital Transformation - Particle Swa...  0.000000  0.000000   \n",
              "MEASURE OF ASYMMETRY                                0.000000  0.000000   \n",
              "What is linear regression? A quick cover with a...  0.000000  0.000000   \n",
              "Correlation VS Covariance: The easy way             0.000000  0.000000   \n",
              "Are Recommender System harming us?                  0.000000  0.000000   \n",
              "1 Line of Python Code That Will Speed Up Your A...  0.271593  0.000000   \n",
              "If You Are Serious About Data Science Job. You ...  0.000000  0.285312   \n",
              "Recommender System With Machine Learning and St...  0.000000  0.000000   \n",
              "Bias detection and mitigation in IBM AutoAI         0.000000  0.000000   \n",
              "Data Engineering: Create your own Dataset           0.000000  0.000000   \n",
              "Graph Neural Networks and Generalizable Models ...  0.000000  0.000000   \n",
              "Fastest Way of Deploying Your Machine Learning ...  0.000000  0.000000   \n",
              "A Novel Approach to Integrate Speech Recognitio...  0.000000  0.000000   \n",
              "3 Lessons Learned in Teaching Machine Learning ...  0.000000  0.000000   \n",
              "Vision Transformer in Galaxy Morphology Classif...  0.000000  0.000000   \n",
              "Exploring Methods of Deep Reinforcement Learnin...  0.000000  0.000000   \n",
              "6 Essential Tips to Solve Data Science Projects     0.000000  0.000000   \n",
              "Data Science Interview Questions My Friends and...  0.000000  0.000000   \n",
              "Understanding Uber’s Generative Teaching Networks   0.000000  0.000000   \n",
              "How to achieve efficient large-batch training?      0.000000  0.000000   \n",
              "How Parallelization and Large Batch Size Improv...  0.000000  0.000000   \n",
              "Why You Need to Know the Inner Workings of Models   0.000000  0.000000   \n",
              "Let’s Build A Simple Object Classification Task I   0.000000  0.000000   \n",
              "\n",
              "                                                     achieve  advanced  \\\n",
              "Machine Learning                                    0.000000  0.000000   \n",
              "Five Advanced Plots in Python - Matplotlib          0.000000  0.450495   \n",
              "How to Make your Computer Talk with Python          0.000000  0.000000   \n",
              "Anomaly Detection on Servo Drives                   0.000000  0.000000   \n",
              "Key takeaways from Kaggle’s most recent time se...  0.000000  0.000000   \n",
              "Animated Mathematical Analysis                      0.000000  0.000000   \n",
              "How to Perform Speech Recognition with Python       0.000000  0.000000   \n",
              "Beyond The Semesters: E04                           0.000000  0.000000   \n",
              "How to improve classification of e-commerce pag...  0.000000  0.000000   \n",
              "Time Series Forecasting with ThymeBoost             0.000000  0.000000   \n",
              "CHAPTER 2: Why I Chose Data Science!                0.000000  0.000000   \n",
              "Training Provably-Robust Neural Networks            0.000000  0.000000   \n",
              "Time Series Forecasting with ThymeBoost             0.000000  0.000000   \n",
              "How to improve classification of e-commerce pag...  0.000000  0.000000   \n",
              "5 Cute Features of CatBoost                         0.000000  0.000000   \n",
              "Variance Inflation Factor (VIF) and it’s relati...  0.000000  0.000000   \n",
              "Beyond The Semesters: E04                           0.000000  0.000000   \n",
              "Efficient Digital Transformation - Particle Swa...  0.000000  0.000000   \n",
              "MEASURE OF ASYMMETRY                                0.000000  0.000000   \n",
              "What is linear regression? A quick cover with a...  0.000000  0.000000   \n",
              "Correlation VS Covariance: The easy way             0.000000  0.000000   \n",
              "Are Recommender System harming us?                  0.000000  0.000000   \n",
              "1 Line of Python Code That Will Speed Up Your A...  0.000000  0.000000   \n",
              "If You Are Serious About Data Science Job. You ...  0.000000  0.000000   \n",
              "Recommender System With Machine Learning and St...  0.000000  0.000000   \n",
              "Bias detection and mitigation in IBM AutoAI         0.000000  0.000000   \n",
              "Data Engineering: Create your own Dataset           0.000000  0.000000   \n",
              "Graph Neural Networks and Generalizable Models ...  0.000000  0.000000   \n",
              "Fastest Way of Deploying Your Machine Learning ...  0.000000  0.000000   \n",
              "A Novel Approach to Integrate Speech Recognitio...  0.000000  0.000000   \n",
              "3 Lessons Learned in Teaching Machine Learning ...  0.000000  0.000000   \n",
              "Vision Transformer in Galaxy Morphology Classif...  0.000000  0.000000   \n",
              "Exploring Methods of Deep Reinforcement Learnin...  0.000000  0.000000   \n",
              "6 Essential Tips to Solve Data Science Projects     0.000000  0.000000   \n",
              "Data Science Interview Questions My Friends and...  0.000000  0.000000   \n",
              "Understanding Uber’s Generative Teaching Networks   0.000000  0.000000   \n",
              "How to achieve efficient large-batch training?      0.467835  0.000000   \n",
              "How Parallelization and Large Batch Size Improv...  0.000000  0.000000   \n",
              "Why You Need to Know the Inner Workings of Models   0.000000  0.000000   \n",
              "Let’s Build A Simple Object Classification Task I   0.000000  0.000000   \n",
              "\n",
              "                                                          ai  analysis  \\\n",
              "Machine Learning                                    0.000000   0.00000   \n",
              "Five Advanced Plots in Python - Matplotlib          0.000000   0.00000   \n",
              "How to Make your Computer Talk with Python          0.000000   0.00000   \n",
              "Anomaly Detection on Servo Drives                   0.000000   0.00000   \n",
              "Key takeaways from Kaggle’s most recent time se...  0.000000   0.00000   \n",
              "Animated Mathematical Analysis                      0.000000   0.57735   \n",
              "How to Perform Speech Recognition with Python       0.000000   0.00000   \n",
              "Beyond The Semesters: E04                           0.000000   0.00000   \n",
              "How to improve classification of e-commerce pag...  0.000000   0.00000   \n",
              "Time Series Forecasting with ThymeBoost             0.000000   0.00000   \n",
              "CHAPTER 2: Why I Chose Data Science!                0.000000   0.00000   \n",
              "Training Provably-Robust Neural Networks            0.000000   0.00000   \n",
              "Time Series Forecasting with ThymeBoost             0.000000   0.00000   \n",
              "How to improve classification of e-commerce pag...  0.000000   0.00000   \n",
              "5 Cute Features of CatBoost                         0.000000   0.00000   \n",
              "Variance Inflation Factor (VIF) and it’s relati...  0.000000   0.00000   \n",
              "Beyond The Semesters: E04                           0.000000   0.00000   \n",
              "Efficient Digital Transformation - Particle Swa...  0.000000   0.00000   \n",
              "MEASURE OF ASYMMETRY                                0.000000   0.00000   \n",
              "What is linear regression? A quick cover with a...  0.000000   0.00000   \n",
              "Correlation VS Covariance: The easy way             0.000000   0.00000   \n",
              "Are Recommender System harming us?                  0.000000   0.00000   \n",
              "1 Line of Python Code That Will Speed Up Your A...  0.271593   0.00000   \n",
              "If You Are Serious About Data Science Job. You ...  0.000000   0.00000   \n",
              "Recommender System With Machine Learning and St...  0.000000   0.00000   \n",
              "Bias detection and mitigation in IBM AutoAI         0.000000   0.00000   \n",
              "Data Engineering: Create your own Dataset           0.000000   0.00000   \n",
              "Graph Neural Networks and Generalizable Models ...  0.000000   0.00000   \n",
              "Fastest Way of Deploying Your Machine Learning ...  0.000000   0.00000   \n",
              "A Novel Approach to Integrate Speech Recognitio...  0.000000   0.00000   \n",
              "3 Lessons Learned in Teaching Machine Learning ...  0.000000   0.00000   \n",
              "Vision Transformer in Galaxy Morphology Classif...  0.000000   0.00000   \n",
              "Exploring Methods of Deep Reinforcement Learnin...  0.000000   0.00000   \n",
              "6 Essential Tips to Solve Data Science Projects     0.000000   0.00000   \n",
              "Data Science Interview Questions My Friends and...  0.000000   0.00000   \n",
              "Understanding Uber’s Generative Teaching Networks   0.000000   0.00000   \n",
              "How to achieve efficient large-batch training?      0.000000   0.00000   \n",
              "How Parallelization and Large Batch Size Improv...  0.000000   0.00000   \n",
              "Why You Need to Know the Inner Workings of Models   0.000000   0.00000   \n",
              "Let’s Build A Simple Object Classification Task I   0.000000   0.00000   \n",
              "\n",
              "                                                         and  animated  \\\n",
              "Machine Learning                                    0.000000   0.00000   \n",
              "Five Advanced Plots in Python - Matplotlib          0.000000   0.00000   \n",
              "How to Make your Computer Talk with Python          0.000000   0.00000   \n",
              "Anomaly Detection on Servo Drives                   0.000000   0.00000   \n",
              "Key takeaways from Kaggle’s most recent time se...  0.000000   0.00000   \n",
              "Animated Mathematical Analysis                      0.000000   0.57735   \n",
              "How to Perform Speech Recognition with Python       0.000000   0.00000   \n",
              "Beyond The Semesters: E04                           0.000000   0.00000   \n",
              "How to improve classification of e-commerce pag...  0.000000   0.00000   \n",
              "Time Series Forecasting with ThymeBoost             0.000000   0.00000   \n",
              "CHAPTER 2: Why I Chose Data Science!                0.000000   0.00000   \n",
              "Training Provably-Robust Neural Networks            0.000000   0.00000   \n",
              "Time Series Forecasting with ThymeBoost             0.000000   0.00000   \n",
              "How to improve classification of e-commerce pag...  0.000000   0.00000   \n",
              "5 Cute Features of CatBoost                         0.000000   0.00000   \n",
              "Variance Inflation Factor (VIF) and it’s relati...  0.209580   0.00000   \n",
              "Beyond The Semesters: E04                           0.000000   0.00000   \n",
              "Efficient Digital Transformation - Particle Swa...  0.000000   0.00000   \n",
              "MEASURE OF ASYMMETRY                                0.000000   0.00000   \n",
              "What is linear regression? A quick cover with a...  0.000000   0.00000   \n",
              "Correlation VS Covariance: The easy way             0.000000   0.00000   \n",
              "Are Recommender System harming us?                  0.000000   0.00000   \n",
              "1 Line of Python Code That Will Speed Up Your A...  0.000000   0.00000   \n",
              "If You Are Serious About Data Science Job. You ...  0.000000   0.00000   \n",
              "Recommender System With Machine Learning and St...  0.306218   0.00000   \n",
              "Bias detection and mitigation in IBM AutoAI         0.262525   0.00000   \n",
              "Data Engineering: Create your own Dataset           0.000000   0.00000   \n",
              "Graph Neural Networks and Generalizable Models ...  0.263898   0.00000   \n",
              "Fastest Way of Deploying Your Machine Learning ...  0.000000   0.00000   \n",
              "A Novel Approach to Integrate Speech Recognitio...  0.000000   0.00000   \n",
              "3 Lessons Learned in Teaching Machine Learning ...  0.000000   0.00000   \n",
              "Vision Transformer in Galaxy Morphology Classif...  0.000000   0.00000   \n",
              "Exploring Methods of Deep Reinforcement Learnin...  0.000000   0.00000   \n",
              "6 Essential Tips to Solve Data Science Projects     0.000000   0.00000   \n",
              "Data Science Interview Questions My Friends and...  0.202508   0.00000   \n",
              "Understanding Uber’s Generative Teaching Networks   0.000000   0.00000   \n",
              "How to achieve efficient large-batch training?      0.000000   0.00000   \n",
              "How Parallelization and Large Batch Size Improv...  0.214150   0.00000   \n",
              "Why You Need to Know the Inner Workings of Models   0.000000   0.00000   \n",
              "Let’s Build A Simple Object Classification Task I   0.000000   0.00000   \n",
              "\n",
              "                                                     anomaly  applications  \\\n",
              "Machine Learning                                    0.000000      0.000000   \n",
              "Five Advanced Plots in Python - Matplotlib          0.000000      0.000000   \n",
              "How to Make your Computer Talk with Python          0.000000      0.000000   \n",
              "Anomaly Detection on Servo Drives                   0.459985      0.000000   \n",
              "Key takeaways from Kaggle’s most recent time se...  0.000000      0.000000   \n",
              "Animated Mathematical Analysis                      0.000000      0.000000   \n",
              "How to Perform Speech Recognition with Python       0.000000      0.000000   \n",
              "Beyond The Semesters: E04                           0.000000      0.000000   \n",
              "How to improve classification of e-commerce pag...  0.000000      0.000000   \n",
              "Time Series Forecasting with ThymeBoost             0.000000      0.000000   \n",
              "CHAPTER 2: Why I Chose Data Science!                0.000000      0.000000   \n",
              "Training Provably-Robust Neural Networks            0.000000      0.000000   \n",
              "Time Series Forecasting with ThymeBoost             0.000000      0.000000   \n",
              "How to improve classification of e-commerce pag...  0.000000      0.000000   \n",
              "5 Cute Features of CatBoost                         0.000000      0.000000   \n",
              "Variance Inflation Factor (VIF) and it’s relati...  0.000000      0.000000   \n",
              "Beyond The Semesters: E04                           0.000000      0.000000   \n",
              "Efficient Digital Transformation - Particle Swa...  0.000000      0.000000   \n",
              "MEASURE OF ASYMMETRY                                0.000000      0.000000   \n",
              "What is linear regression? A quick cover with a...  0.000000      0.000000   \n",
              "Correlation VS Covariance: The easy way             0.000000      0.000000   \n",
              "Are Recommender System harming us?                  0.000000      0.000000   \n",
              "1 Line of Python Code That Will Speed Up Your A...  0.000000      0.000000   \n",
              "If You Are Serious About Data Science Job. You ...  0.000000      0.000000   \n",
              "Recommender System With Machine Learning and St...  0.000000      0.000000   \n",
              "Bias detection and mitigation in IBM AutoAI         0.000000      0.000000   \n",
              "Data Engineering: Create your own Dataset           0.000000      0.000000   \n",
              "Graph Neural Networks and Generalizable Models ...  0.000000      0.000000   \n",
              "Fastest Way of Deploying Your Machine Learning ...  0.000000      0.000000   \n",
              "A Novel Approach to Integrate Speech Recognitio...  0.000000      0.000000   \n",
              "3 Lessons Learned in Teaching Machine Learning ...  0.000000      0.000000   \n",
              "Vision Transformer in Galaxy Morphology Classif...  0.000000      0.000000   \n",
              "Exploring Methods of Deep Reinforcement Learnin...  0.000000      0.384911   \n",
              "6 Essential Tips to Solve Data Science Projects     0.000000      0.000000   \n",
              "Data Science Interview Questions My Friends and...  0.000000      0.000000   \n",
              "Understanding Uber’s Generative Teaching Networks   0.000000      0.000000   \n",
              "How to achieve efficient large-batch training?      0.000000      0.000000   \n",
              "How Parallelization and Large Batch Size Improv...  0.000000      0.000000   \n",
              "Why You Need to Know the Inner Workings of Models   0.000000      0.000000   \n",
              "Let’s Build A Simple Object Classification Task I   0.000000      0.000000   \n",
              "\n",
              "                                                    ...    vision        vs  \\\n",
              "Machine Learning                                    ...  0.000000  0.000000   \n",
              "Five Advanced Plots in Python - Matplotlib          ...  0.000000  0.000000   \n",
              "How to Make your Computer Talk with Python          ...  0.000000  0.000000   \n",
              "Anomaly Detection on Servo Drives                   ...  0.000000  0.000000   \n",
              "Key takeaways from Kaggle’s most recent time se...  ...  0.000000  0.000000   \n",
              "Animated Mathematical Analysis                      ...  0.000000  0.000000   \n",
              "How to Perform Speech Recognition with Python       ...  0.000000  0.000000   \n",
              "Beyond The Semesters: E04                           ...  0.000000  0.000000   \n",
              "How to improve classification of e-commerce pag...  ...  0.000000  0.000000   \n",
              "Time Series Forecasting with ThymeBoost             ...  0.000000  0.000000   \n",
              "CHAPTER 2: Why I Chose Data Science!                ...  0.000000  0.000000   \n",
              "Training Provably-Robust Neural Networks            ...  0.000000  0.000000   \n",
              "Time Series Forecasting with ThymeBoost             ...  0.000000  0.000000   \n",
              "How to improve classification of e-commerce pag...  ...  0.000000  0.000000   \n",
              "5 Cute Features of CatBoost                         ...  0.000000  0.000000   \n",
              "Variance Inflation Factor (VIF) and it’s relati...  ...  0.000000  0.000000   \n",
              "Beyond The Semesters: E04                           ...  0.000000  0.000000   \n",
              "Efficient Digital Transformation - Particle Swa...  ...  0.000000  0.000000   \n",
              "MEASURE OF ASYMMETRY                                ...  0.000000  0.000000   \n",
              "What is linear regression? A quick cover with a...  ...  0.000000  0.000000   \n",
              "Correlation VS Covariance: The easy way             ...  0.000000  0.440331   \n",
              "Are Recommender System harming us?                  ...  0.000000  0.000000   \n",
              "1 Line of Python Code That Will Speed Up Your A...  ...  0.000000  0.000000   \n",
              "If You Are Serious About Data Science Job. You ...  ...  0.000000  0.000000   \n",
              "Recommender System With Machine Learning and St...  ...  0.000000  0.000000   \n",
              "Bias detection and mitigation in IBM AutoAI         ...  0.000000  0.000000   \n",
              "Data Engineering: Create your own Dataset           ...  0.000000  0.000000   \n",
              "Graph Neural Networks and Generalizable Models ...  ...  0.000000  0.000000   \n",
              "Fastest Way of Deploying Your Machine Learning ...  ...  0.000000  0.000000   \n",
              "A Novel Approach to Integrate Speech Recognitio...  ...  0.000000  0.000000   \n",
              "3 Lessons Learned in Teaching Machine Learning ...  ...  0.000000  0.000000   \n",
              "Vision Transformer in Galaxy Morphology Classif...  ...  0.450495  0.000000   \n",
              "Exploring Methods of Deep Reinforcement Learnin...  ...  0.000000  0.000000   \n",
              "6 Essential Tips to Solve Data Science Projects     ...  0.000000  0.000000   \n",
              "Data Science Interview Questions My Friends and...  ...  0.000000  0.000000   \n",
              "Understanding Uber’s Generative Teaching Networks   ...  0.000000  0.000000   \n",
              "How to achieve efficient large-batch training?      ...  0.000000  0.000000   \n",
              "How Parallelization and Large Batch Size Improv...  ...  0.000000  0.000000   \n",
              "Why You Need to Know the Inner Workings of Models   ...  0.000000  0.000000   \n",
              "Let’s Build A Simple Object Classification Task I   ...  0.000000  0.000000   \n",
              "\n",
              "                                                         way      what  \\\n",
              "Machine Learning                                    0.000000  0.000000   \n",
              "Five Advanced Plots in Python - Matplotlib          0.000000  0.000000   \n",
              "How to Make your Computer Talk with Python          0.000000  0.000000   \n",
              "Anomaly Detection on Servo Drives                   0.000000  0.000000   \n",
              "Key takeaways from Kaggle’s most recent time se...  0.000000  0.000000   \n",
              "Animated Mathematical Analysis                      0.000000  0.000000   \n",
              "How to Perform Speech Recognition with Python       0.000000  0.000000   \n",
              "Beyond The Semesters: E04                           0.000000  0.000000   \n",
              "How to improve classification of e-commerce pag...  0.000000  0.000000   \n",
              "Time Series Forecasting with ThymeBoost             0.000000  0.000000   \n",
              "CHAPTER 2: Why I Chose Data Science!                0.000000  0.000000   \n",
              "Training Provably-Robust Neural Networks            0.000000  0.000000   \n",
              "Time Series Forecasting with ThymeBoost             0.000000  0.000000   \n",
              "How to improve classification of e-commerce pag...  0.000000  0.000000   \n",
              "5 Cute Features of CatBoost                         0.000000  0.000000   \n",
              "Variance Inflation Factor (VIF) and it’s relati...  0.000000  0.000000   \n",
              "Beyond The Semesters: E04                           0.000000  0.000000   \n",
              "Efficient Digital Transformation - Particle Swa...  0.000000  0.000000   \n",
              "MEASURE OF ASYMMETRY                                0.000000  0.000000   \n",
              "What is linear regression? A quick cover with a...  0.000000  0.369871   \n",
              "Correlation VS Covariance: The easy way             0.375238  0.000000   \n",
              "Are Recommender System harming us?                  0.000000  0.000000   \n",
              "1 Line of Python Code That Will Speed Up Your A...  0.000000  0.000000   \n",
              "If You Are Serious About Data Science Job. You ...  0.000000  0.000000   \n",
              "Recommender System With Machine Learning and St...  0.000000  0.000000   \n",
              "Bias detection and mitigation in IBM AutoAI         0.000000  0.000000   \n",
              "Data Engineering: Create your own Dataset           0.000000  0.000000   \n",
              "Graph Neural Networks and Generalizable Models ...  0.000000  0.000000   \n",
              "Fastest Way of Deploying Your Machine Learning ...  0.380404  0.000000   \n",
              "A Novel Approach to Integrate Speech Recognitio...  0.000000  0.000000   \n",
              "3 Lessons Learned in Teaching Machine Learning ...  0.000000  0.000000   \n",
              "Vision Transformer in Galaxy Morphology Classif...  0.000000  0.000000   \n",
              "Exploring Methods of Deep Reinforcement Learnin...  0.000000  0.000000   \n",
              "6 Essential Tips to Solve Data Science Projects     0.000000  0.000000   \n",
              "Data Science Interview Questions My Friends and...  0.000000  0.000000   \n",
              "Understanding Uber’s Generative Teaching Networks   0.000000  0.000000   \n",
              "How to achieve efficient large-batch training?      0.000000  0.000000   \n",
              "How Parallelization and Large Batch Size Improv...  0.000000  0.000000   \n",
              "Why You Need to Know the Inner Workings of Models   0.000000  0.000000   \n",
              "Let’s Build A Simple Object Classification Task I   0.000000  0.000000   \n",
              "\n",
              "                                                         why      will  \\\n",
              "Machine Learning                                    0.000000  0.000000   \n",
              "Five Advanced Plots in Python - Matplotlib          0.000000  0.000000   \n",
              "How to Make your Computer Talk with Python          0.000000  0.000000   \n",
              "Anomaly Detection on Servo Drives                   0.000000  0.000000   \n",
              "Key takeaways from Kaggle’s most recent time se...  0.000000  0.000000   \n",
              "Animated Mathematical Analysis                      0.000000  0.000000   \n",
              "How to Perform Speech Recognition with Python       0.000000  0.000000   \n",
              "Beyond The Semesters: E04                           0.000000  0.000000   \n",
              "How to improve classification of e-commerce pag...  0.000000  0.000000   \n",
              "Time Series Forecasting with ThymeBoost             0.000000  0.000000   \n",
              "CHAPTER 2: Why I Chose Data Science!                0.445826  0.000000   \n",
              "Training Provably-Robust Neural Networks            0.000000  0.000000   \n",
              "Time Series Forecasting with ThymeBoost             0.000000  0.000000   \n",
              "How to improve classification of e-commerce pag...  0.000000  0.000000   \n",
              "5 Cute Features of CatBoost                         0.000000  0.000000   \n",
              "Variance Inflation Factor (VIF) and it’s relati...  0.000000  0.000000   \n",
              "Beyond The Semesters: E04                           0.000000  0.000000   \n",
              "Efficient Digital Transformation - Particle Swa...  0.000000  0.000000   \n",
              "MEASURE OF ASYMMETRY                                0.000000  0.000000   \n",
              "What is linear regression? A quick cover with a...  0.000000  0.000000   \n",
              "Correlation VS Covariance: The easy way             0.000000  0.000000   \n",
              "Are Recommender System harming us?                  0.000000  0.000000   \n",
              "1 Line of Python Code That Will Speed Up Your A...  0.000000  0.271593   \n",
              "If You Are Serious About Data Science Job. You ...  0.000000  0.000000   \n",
              "Recommender System With Machine Learning and St...  0.000000  0.000000   \n",
              "Bias detection and mitigation in IBM AutoAI         0.000000  0.000000   \n",
              "Data Engineering: Create your own Dataset           0.000000  0.000000   \n",
              "Graph Neural Networks and Generalizable Models ...  0.000000  0.000000   \n",
              "Fastest Way of Deploying Your Machine Learning ...  0.000000  0.000000   \n",
              "A Novel Approach to Integrate Speech Recognitio...  0.000000  0.000000   \n",
              "3 Lessons Learned in Teaching Machine Learning ...  0.000000  0.000000   \n",
              "Vision Transformer in Galaxy Morphology Classif...  0.000000  0.000000   \n",
              "Exploring Methods of Deep Reinforcement Learnin...  0.000000  0.000000   \n",
              "6 Essential Tips to Solve Data Science Projects     0.000000  0.000000   \n",
              "Data Science Interview Questions My Friends and...  0.000000  0.000000   \n",
              "Understanding Uber’s Generative Teaching Networks   0.000000  0.000000   \n",
              "How to achieve efficient large-batch training?      0.000000  0.000000   \n",
              "How Parallelization and Large Batch Size Improv...  0.000000  0.000000   \n",
              "Why You Need to Know the Inner Workings of Models   0.327735  0.000000   \n",
              "Let’s Build A Simple Object Classification Task I   0.000000  0.000000   \n",
              "\n",
              "                                                        with  workings  \\\n",
              "Machine Learning                                    0.000000  0.000000   \n",
              "Five Advanced Plots in Python - Matplotlib          0.000000  0.000000   \n",
              "How to Make your Computer Talk with Python          0.249731  0.000000   \n",
              "Anomaly Detection on Servo Drives                   0.000000  0.000000   \n",
              "Key takeaways from Kaggle’s most recent time se...  0.000000  0.000000   \n",
              "Animated Mathematical Analysis                      0.000000  0.000000   \n",
              "How to Perform Speech Recognition with Python       0.280999  0.000000   \n",
              "Beyond The Semesters: E04                           0.000000  0.000000   \n",
              "How to improve classification of e-commerce pag...  0.000000  0.000000   \n",
              "Time Series Forecasting with ThymeBoost             0.324860  0.000000   \n",
              "CHAPTER 2: Why I Chose Data Science!                0.000000  0.000000   \n",
              "Training Provably-Robust Neural Networks            0.000000  0.000000   \n",
              "Time Series Forecasting with ThymeBoost             0.324860  0.000000   \n",
              "How to improve classification of e-commerce pag...  0.000000  0.000000   \n",
              "5 Cute Features of CatBoost                         0.000000  0.000000   \n",
              "Variance Inflation Factor (VIF) and it’s relati...  0.188769  0.000000   \n",
              "Beyond The Semesters: E04                           0.000000  0.000000   \n",
              "Efficient Digital Transformation - Particle Swa...  0.000000  0.000000   \n",
              "MEASURE OF ASYMMETRY                                0.000000  0.000000   \n",
              "What is linear regression? A quick cover with a...  0.205839  0.000000   \n",
              "Correlation VS Covariance: The easy way             0.000000  0.000000   \n",
              "Are Recommender System harming us?                  0.000000  0.000000   \n",
              "1 Line of Python Code That Will Speed Up Your A...  0.000000  0.000000   \n",
              "If You Are Serious About Data Science Job. You ...  0.000000  0.000000   \n",
              "Recommender System With Machine Learning and St...  0.275811  0.000000   \n",
              "Bias detection and mitigation in IBM AutoAI         0.000000  0.000000   \n",
              "Data Engineering: Create your own Dataset           0.000000  0.000000   \n",
              "Graph Neural Networks and Generalizable Models ...  0.000000  0.000000   \n",
              "Fastest Way of Deploying Your Machine Learning ...  0.000000  0.000000   \n",
              "A Novel Approach to Integrate Speech Recognitio...  0.000000  0.000000   \n",
              "3 Lessons Learned in Teaching Machine Learning ...  0.000000  0.000000   \n",
              "Vision Transformer in Galaxy Morphology Classif...  0.000000  0.000000   \n",
              "Exploring Methods of Deep Reinforcement Learnin...  0.214209  0.000000   \n",
              "6 Essential Tips to Solve Data Science Projects     0.000000  0.000000   \n",
              "Data Science Interview Questions My Friends and...  0.000000  0.000000   \n",
              "Understanding Uber’s Generative Teaching Networks   0.000000  0.000000   \n",
              "How to achieve efficient large-batch training?      0.000000  0.000000   \n",
              "How Parallelization and Large Batch Size Improv...  0.000000  0.000000   \n",
              "Why You Need to Know the Inner Workings of Models   0.000000  0.384588   \n",
              "Let’s Build A Simple Object Classification Task I   0.000000  0.000000   \n",
              "\n",
              "                                                         you      your  \n",
              "Machine Learning                                    0.000000  0.000000  \n",
              "Five Advanced Plots in Python - Matplotlib          0.000000  0.000000  \n",
              "How to Make your Computer Talk with Python          0.000000  0.316067  \n",
              "Anomaly Detection on Servo Drives                   0.000000  0.000000  \n",
              "Key takeaways from Kaggle’s most recent time se...  0.000000  0.000000  \n",
              "Animated Mathematical Analysis                      0.000000  0.000000  \n",
              "How to Perform Speech Recognition with Python       0.000000  0.000000  \n",
              "Beyond The Semesters: E04                           0.000000  0.000000  \n",
              "How to improve classification of e-commerce pag...  0.000000  0.000000  \n",
              "Time Series Forecasting with ThymeBoost             0.000000  0.000000  \n",
              "CHAPTER 2: Why I Chose Data Science!                0.000000  0.000000  \n",
              "Training Provably-Robust Neural Networks            0.000000  0.000000  \n",
              "Time Series Forecasting with ThymeBoost             0.000000  0.000000  \n",
              "How to improve classification of e-commerce pag...  0.000000  0.000000  \n",
              "5 Cute Features of CatBoost                         0.000000  0.000000  \n",
              "Variance Inflation Factor (VIF) and it’s relati...  0.000000  0.000000  \n",
              "Beyond The Semesters: E04                           0.000000  0.000000  \n",
              "Efficient Digital Transformation - Particle Swa...  0.000000  0.000000  \n",
              "MEASURE OF ASYMMETRY                                0.000000  0.000000  \n",
              "What is linear regression? A quick cover with a...  0.000000  0.000000  \n",
              "Correlation VS Covariance: The easy way             0.000000  0.000000  \n",
              "Are Recommender System harming us?                  0.000000  0.000000  \n",
              "1 Line of Python Code That Will Speed Up Your A...  0.000000  0.191295  \n",
              "If You Are Serious About Data Science Job. You ...  0.486269  0.000000  \n",
              "Recommender System With Machine Learning and St...  0.000000  0.000000  \n",
              "Bias detection and mitigation in IBM AutoAI         0.000000  0.000000  \n",
              "Data Engineering: Create your own Dataset           0.000000  0.317303  \n",
              "Graph Neural Networks and Generalizable Models ...  0.000000  0.000000  \n",
              "Fastest Way of Deploying Your Machine Learning ...  0.000000  0.314414  \n",
              "A Novel Approach to Integrate Speech Recognitio...  0.000000  0.000000  \n",
              "3 Lessons Learned in Teaching Machine Learning ...  0.000000  0.000000  \n",
              "Vision Transformer in Galaxy Morphology Classif...  0.000000  0.000000  \n",
              "Exploring Methods of Deep Reinforcement Learnin...  0.000000  0.000000  \n",
              "6 Essential Tips to Solve Data Science Projects     0.000000  0.000000  \n",
              "Data Science Interview Questions My Friends and...  0.000000  0.000000  \n",
              "Understanding Uber’s Generative Teaching Networks   0.000000  0.000000  \n",
              "How to achieve efficient large-batch training?      0.000000  0.000000  \n",
              "How Parallelization and Large Batch Size Improv...  0.000000  0.000000  \n",
              "Why You Need to Know the Inner Workings of Models   0.327735  0.000000  \n",
              "Let’s Build A Simple Object Classification Task I   0.000000  0.000000  \n",
              "\n",
              "[40 rows x 184 columns]"
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf=TfidfVectorizer(use_idf=True, smooth_idf=False)\n",
        "\n",
        "dfTFIDF = pd.DataFrame(tfidf.fit_transform(documents).toarray(), index=documents, columns=tfidf.get_feature_names_out())\n",
        "dfTFIDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "id": "b1436cd3",
      "metadata": {
        "id": "b1436cd3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "of           2.491655\n",
              "to           2.491655\n",
              "with         2.609438\n",
              "and          2.897120\n",
              "how          2.897120\n",
              "               ...   \n",
              "integrate    4.688879\n",
              "interview    4.688879\n",
              "into         4.688879\n",
              "need         4.688879\n",
              "measure      4.688879\n",
              "Length: 184, dtype: float64"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.Series(tfidf.idf_, index=tfidf.get_feature_names_out()).sort_values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "id": "c07325d2",
      "metadata": {
        "id": "c07325d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Machine Learning                                                                                    0.763355\n",
              "Recommender System With Machine Learning and Statistics                                             0.364334\n",
              "Fastest Way of Deploying Your Machine Learning Models                                               0.328159\n",
              "How to Perform Speech Recognition with Python                                                       0.265814\n",
              "3 Lessons Learned in Teaching Machine Learning for Earth Observation Techniques                     0.258540\n",
              "How to achieve efficient large-batch training?                                                      0.246288\n",
              "How to Make your Computer Talk with Python                                                          0.236235\n",
              "How to improve classification of e-commerce pages, incorporating multiple modalities                0.221282\n",
              "How to improve classification of e-commerce pages, incorporating multiple modalities                0.221282\n",
              "Exploring Methods of Deep Reinforcement Learning with NLP Applications                              0.131599\n",
              "How Parallelization and Large Batch Size Improve the Performance of Deep Neural Networks.           0.104882\n",
              "6 Essential Tips to Solve Data Science Projects                                                     0.098065\n",
              "Why You Need to Know the Inner Workings of Models                                                   0.086083\n",
              "A Novel Approach to Integrate Speech Recognition into Authentication Systems                        0.080482\n",
              "1 Line of Python Code That Will Speed Up Your AI by Up to 6x                                        0.060792\n",
              "Graph Neural Networks and Generalizable Models in Neuroscience                                      0.000000\n",
              "Data Engineering: Create your own Dataset                                                           0.000000\n",
              "Bias detection and mitigation in IBM AutoAI                                                         0.000000\n",
              "Data Science Interview Questions My Friends and I got asked recently (III)                          0.000000\n",
              "Understanding Uber’s Generative Teaching Networks                                                   0.000000\n",
              "If You Are Serious About Data Science Job. You Must Know These 3 Things.                            0.000000\n",
              "Vision Transformer in Galaxy Morphology Classification                                              0.000000\n",
              "What is linear regression? A quick cover with a tutorial                                            0.000000\n",
              "Correlation VS Covariance: The easy way                                                             0.000000\n",
              "Five Advanced Plots in Python - Matplotlib                                                          0.000000\n",
              "Anomaly Detection on Servo Drives                                                                   0.000000\n",
              "Key takeaways from Kaggle’s most recent time series competition - Ventilator Pressure Prediction    0.000000\n",
              "Animated Mathematical Analysis                                                                      0.000000\n",
              "Beyond The Semesters: E04                                                                           0.000000\n",
              "Time Series Forecasting with ThymeBoost                                                             0.000000\n",
              "Are Recommender System harming us?                                                                  0.000000\n",
              "CHAPTER 2: Why I Chose Data Science!                                                                0.000000\n",
              "Time Series Forecasting with ThymeBoost                                                             0.000000\n",
              "5 Cute Features of CatBoost                                                                         0.000000\n",
              "Variance Inflation Factor (VIF) and it’s relationship with multicollinearity&nbsp;.                 0.000000\n",
              "Beyond The Semesters: E04                                                                           0.000000\n",
              "Efficient Digital Transformation - Particle Swarm Optimiser                                         0.000000\n",
              "MEASURE OF ASYMMETRY                                                                                0.000000\n",
              "Training Provably-Robust Neural Networks                                                            0.000000\n",
              "Let’s Build A Simple Object Classification Task I                                                   0.000000\n",
              "dtype: float64"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"how to machine learning\"\n",
        "query = tfidf.transform([query]).toarray()[0] # convert the query into tfidf vector using the trained tfidf model with learned vocab\n",
        "1-dfTFIDF.apply(lambda x: cosine(x, query), axis=1).sort_values()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9717a8ef",
      "metadata": {},
      "source": [
        "----------\n",
        "my own approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "id": "6fe39e13",
      "metadata": {
        "id": "6fe39e13",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Custom TF-IDF Matrix:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>achieve</th>\n",
              "      <th>advanced</th>\n",
              "      <th>ai</th>\n",
              "      <th>analysis</th>\n",
              "      <th>animated</th>\n",
              "      <th>anomaly</th>\n",
              "      <th>applications</th>\n",
              "      <th>approach</th>\n",
              "      <th>asked</th>\n",
              "      <th>asymmetry</th>\n",
              "      <th>...</th>\n",
              "      <th>uber</th>\n",
              "      <th>understanding</th>\n",
              "      <th>us</th>\n",
              "      <th>variance</th>\n",
              "      <th>ventilator</th>\n",
              "      <th>vif</th>\n",
              "      <th>vision</th>\n",
              "      <th>vs</th>\n",
              "      <th>way</th>\n",
              "      <th>workings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>machine learning</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>five advanced plots python matplotlib</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.604085</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>make computer talk python</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>anomaly detection servo drives</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.755106</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>key takeaways kaggle recent time series competition ventilator pressure prediction</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.302042</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>animated mathematical analysis</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.006808</td>\n",
              "      <td>1.006808</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>perform speech recognition python</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>beyond semesters</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>improve classification pages incorporating multiple modalities</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time series forecasting thymeboost</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>chapter chose data science</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>training neural networks</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time series forecasting thymeboost</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>improve classification pages incorporating multiple modalities</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cute features catboost</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>variance inflation factor vif relationship multicollinearity nbsp</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.431489</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.431489</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>beyond semesters</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>efficient digital transformation particle swarm optimiser</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>measure asymmetry</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.510212</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>linear regression quick cover tutorial</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>correlation vs covariance easy way</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.604085</td>\n",
              "      <td>0.522992</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recommender system harming us</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.755106</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>line python code speed ai</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.604085</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>serious data science job must know things</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recommender system machine learning statistics</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bias detection mitigation ibm autoai</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>data engineering create dataset</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>graph neural networks generalizable models neuroscience</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fastest way deploying machine learning models</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.435827</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>novel approach integrate speech recognition authentication systems</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.431489</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lessons learned teaching machine learning earth observation techniques</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vision transformer galaxy morphology classification</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.604085</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>exploring methods deep reinforcement learning nlp applications</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.431489</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>essential tips solve data science projects</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>data science interview questions friends got asked recently iii</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.335603</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>understanding uber generative teaching networks</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.604085</td>\n",
              "      <td>0.604085</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>achieve efficient training</th>\n",
              "      <td>1.006808</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>parallelization large batch size improve performance deep neural networks</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>need know inner workings models</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.604085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>let build simple object classification task</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40 rows × 151 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     achieve  advanced  \\\n",
              "machine learning                                    0.000000  0.000000   \n",
              "five advanced plots python matplotlib               0.000000  0.604085   \n",
              "make computer talk python                           0.000000  0.000000   \n",
              "anomaly detection servo drives                      0.000000  0.000000   \n",
              "key takeaways kaggle recent time series competi...  0.000000  0.000000   \n",
              "animated mathematical analysis                      0.000000  0.000000   \n",
              "perform speech recognition python                   0.000000  0.000000   \n",
              "beyond semesters                                    0.000000  0.000000   \n",
              "improve classification pages incorporating mult...  0.000000  0.000000   \n",
              "time series forecasting thymeboost                  0.000000  0.000000   \n",
              "chapter chose data science                          0.000000  0.000000   \n",
              "training neural networks                            0.000000  0.000000   \n",
              "time series forecasting thymeboost                  0.000000  0.000000   \n",
              "improve classification pages incorporating mult...  0.000000  0.000000   \n",
              "cute features catboost                              0.000000  0.000000   \n",
              "variance inflation factor vif relationship mult...  0.000000  0.000000   \n",
              "beyond semesters                                    0.000000  0.000000   \n",
              "efficient digital transformation particle swarm...  0.000000  0.000000   \n",
              "measure asymmetry                                   0.000000  0.000000   \n",
              "linear regression quick cover tutorial              0.000000  0.000000   \n",
              "correlation vs covariance easy way                  0.000000  0.000000   \n",
              "recommender system harming us                       0.000000  0.000000   \n",
              "line python code speed ai                           0.000000  0.000000   \n",
              "serious data science job must know things           0.000000  0.000000   \n",
              "recommender system machine learning statistics      0.000000  0.000000   \n",
              "bias detection mitigation ibm autoai                0.000000  0.000000   \n",
              "data engineering create dataset                     0.000000  0.000000   \n",
              "graph neural networks generalizable models neur...  0.000000  0.000000   \n",
              "fastest way deploying machine learning models       0.000000  0.000000   \n",
              "novel approach integrate speech recognition aut...  0.000000  0.000000   \n",
              "lessons learned teaching machine learning earth...  0.000000  0.000000   \n",
              "vision transformer galaxy morphology classifica...  0.000000  0.000000   \n",
              "exploring methods deep reinforcement learning n...  0.000000  0.000000   \n",
              "essential tips solve data science projects          0.000000  0.000000   \n",
              "data science interview questions friends got as...  0.000000  0.000000   \n",
              "understanding uber generative teaching networks     0.000000  0.000000   \n",
              "achieve efficient training                          1.006808  0.000000   \n",
              "parallelization large batch size improve perfor...  0.000000  0.000000   \n",
              "need know inner workings models                     0.000000  0.000000   \n",
              "let build simple object classification task         0.000000  0.000000   \n",
              "\n",
              "                                                          ai  analysis  \\\n",
              "machine learning                                    0.000000  0.000000   \n",
              "five advanced plots python matplotlib               0.000000  0.000000   \n",
              "make computer talk python                           0.000000  0.000000   \n",
              "anomaly detection servo drives                      0.000000  0.000000   \n",
              "key takeaways kaggle recent time series competi...  0.000000  0.000000   \n",
              "animated mathematical analysis                      0.000000  1.006808   \n",
              "perform speech recognition python                   0.000000  0.000000   \n",
              "beyond semesters                                    0.000000  0.000000   \n",
              "improve classification pages incorporating mult...  0.000000  0.000000   \n",
              "time series forecasting thymeboost                  0.000000  0.000000   \n",
              "chapter chose data science                          0.000000  0.000000   \n",
              "training neural networks                            0.000000  0.000000   \n",
              "time series forecasting thymeboost                  0.000000  0.000000   \n",
              "improve classification pages incorporating mult...  0.000000  0.000000   \n",
              "cute features catboost                              0.000000  0.000000   \n",
              "variance inflation factor vif relationship mult...  0.000000  0.000000   \n",
              "beyond semesters                                    0.000000  0.000000   \n",
              "efficient digital transformation particle swarm...  0.000000  0.000000   \n",
              "measure asymmetry                                   0.000000  0.000000   \n",
              "linear regression quick cover tutorial              0.000000  0.000000   \n",
              "correlation vs covariance easy way                  0.000000  0.000000   \n",
              "recommender system harming us                       0.000000  0.000000   \n",
              "line python code speed ai                           0.604085  0.000000   \n",
              "serious data science job must know things           0.000000  0.000000   \n",
              "recommender system machine learning statistics      0.000000  0.000000   \n",
              "bias detection mitigation ibm autoai                0.000000  0.000000   \n",
              "data engineering create dataset                     0.000000  0.000000   \n",
              "graph neural networks generalizable models neur...  0.000000  0.000000   \n",
              "fastest way deploying machine learning models       0.000000  0.000000   \n",
              "novel approach integrate speech recognition aut...  0.000000  0.000000   \n",
              "lessons learned teaching machine learning earth...  0.000000  0.000000   \n",
              "vision transformer galaxy morphology classifica...  0.000000  0.000000   \n",
              "exploring methods deep reinforcement learning n...  0.000000  0.000000   \n",
              "essential tips solve data science projects          0.000000  0.000000   \n",
              "data science interview questions friends got as...  0.000000  0.000000   \n",
              "understanding uber generative teaching networks     0.000000  0.000000   \n",
              "achieve efficient training                          0.000000  0.000000   \n",
              "parallelization large batch size improve perfor...  0.000000  0.000000   \n",
              "need know inner workings models                     0.000000  0.000000   \n",
              "let build simple object classification task         0.000000  0.000000   \n",
              "\n",
              "                                                    animated   anomaly  \\\n",
              "machine learning                                    0.000000  0.000000   \n",
              "five advanced plots python matplotlib               0.000000  0.000000   \n",
              "make computer talk python                           0.000000  0.000000   \n",
              "anomaly detection servo drives                      0.000000  0.755106   \n",
              "key takeaways kaggle recent time series competi...  0.000000  0.000000   \n",
              "animated mathematical analysis                      1.006808  0.000000   \n",
              "perform speech recognition python                   0.000000  0.000000   \n",
              "beyond semesters                                    0.000000  0.000000   \n",
              "improve classification pages incorporating mult...  0.000000  0.000000   \n",
              "time series forecasting thymeboost                  0.000000  0.000000   \n",
              "chapter chose data science                          0.000000  0.000000   \n",
              "training neural networks                            0.000000  0.000000   \n",
              "time series forecasting thymeboost                  0.000000  0.000000   \n",
              "improve classification pages incorporating mult...  0.000000  0.000000   \n",
              "cute features catboost                              0.000000  0.000000   \n",
              "variance inflation factor vif relationship mult...  0.000000  0.000000   \n",
              "beyond semesters                                    0.000000  0.000000   \n",
              "efficient digital transformation particle swarm...  0.000000  0.000000   \n",
              "measure asymmetry                                   0.000000  0.000000   \n",
              "linear regression quick cover tutorial              0.000000  0.000000   \n",
              "correlation vs covariance easy way                  0.000000  0.000000   \n",
              "recommender system harming us                       0.000000  0.000000   \n",
              "line python code speed ai                           0.000000  0.000000   \n",
              "serious data science job must know things           0.000000  0.000000   \n",
              "recommender system machine learning statistics      0.000000  0.000000   \n",
              "bias detection mitigation ibm autoai                0.000000  0.000000   \n",
              "data engineering create dataset                     0.000000  0.000000   \n",
              "graph neural networks generalizable models neur...  0.000000  0.000000   \n",
              "fastest way deploying machine learning models       0.000000  0.000000   \n",
              "novel approach integrate speech recognition aut...  0.000000  0.000000   \n",
              "lessons learned teaching machine learning earth...  0.000000  0.000000   \n",
              "vision transformer galaxy morphology classifica...  0.000000  0.000000   \n",
              "exploring methods deep reinforcement learning n...  0.000000  0.000000   \n",
              "essential tips solve data science projects          0.000000  0.000000   \n",
              "data science interview questions friends got as...  0.000000  0.000000   \n",
              "understanding uber generative teaching networks     0.000000  0.000000   \n",
              "achieve efficient training                          0.000000  0.000000   \n",
              "parallelization large batch size improve perfor...  0.000000  0.000000   \n",
              "need know inner workings models                     0.000000  0.000000   \n",
              "let build simple object classification task         0.000000  0.000000   \n",
              "\n",
              "                                                    applications  approach  \\\n",
              "machine learning                                        0.000000  0.000000   \n",
              "five advanced plots python matplotlib                   0.000000  0.000000   \n",
              "make computer talk python                               0.000000  0.000000   \n",
              "anomaly detection servo drives                          0.000000  0.000000   \n",
              "key takeaways kaggle recent time series competi...      0.000000  0.000000   \n",
              "animated mathematical analysis                          0.000000  0.000000   \n",
              "perform speech recognition python                       0.000000  0.000000   \n",
              "beyond semesters                                        0.000000  0.000000   \n",
              "improve classification pages incorporating mult...      0.000000  0.000000   \n",
              "time series forecasting thymeboost                      0.000000  0.000000   \n",
              "chapter chose data science                              0.000000  0.000000   \n",
              "training neural networks                                0.000000  0.000000   \n",
              "time series forecasting thymeboost                      0.000000  0.000000   \n",
              "improve classification pages incorporating mult...      0.000000  0.000000   \n",
              "cute features catboost                                  0.000000  0.000000   \n",
              "variance inflation factor vif relationship mult...      0.000000  0.000000   \n",
              "beyond semesters                                        0.000000  0.000000   \n",
              "efficient digital transformation particle swarm...      0.000000  0.000000   \n",
              "measure asymmetry                                       0.000000  0.000000   \n",
              "linear regression quick cover tutorial                  0.000000  0.000000   \n",
              "correlation vs covariance easy way                      0.000000  0.000000   \n",
              "recommender system harming us                           0.000000  0.000000   \n",
              "line python code speed ai                               0.000000  0.000000   \n",
              "serious data science job must know things               0.000000  0.000000   \n",
              "recommender system machine learning statistics          0.000000  0.000000   \n",
              "bias detection mitigation ibm autoai                    0.000000  0.000000   \n",
              "data engineering create dataset                         0.000000  0.000000   \n",
              "graph neural networks generalizable models neur...      0.000000  0.000000   \n",
              "fastest way deploying machine learning models           0.000000  0.000000   \n",
              "novel approach integrate speech recognition aut...      0.000000  0.431489   \n",
              "lessons learned teaching machine learning earth...      0.000000  0.000000   \n",
              "vision transformer galaxy morphology classifica...      0.000000  0.000000   \n",
              "exploring methods deep reinforcement learning n...      0.431489  0.000000   \n",
              "essential tips solve data science projects              0.000000  0.000000   \n",
              "data science interview questions friends got as...      0.000000  0.000000   \n",
              "understanding uber generative teaching networks         0.000000  0.000000   \n",
              "achieve efficient training                              0.000000  0.000000   \n",
              "parallelization large batch size improve perfor...      0.000000  0.000000   \n",
              "need know inner workings models                         0.000000  0.000000   \n",
              "let build simple object classification task             0.000000  0.000000   \n",
              "\n",
              "                                                       asked  asymmetry  ...  \\\n",
              "machine learning                                    0.000000   0.000000  ...   \n",
              "five advanced plots python matplotlib               0.000000   0.000000  ...   \n",
              "make computer talk python                           0.000000   0.000000  ...   \n",
              "anomaly detection servo drives                      0.000000   0.000000  ...   \n",
              "key takeaways kaggle recent time series competi...  0.000000   0.000000  ...   \n",
              "animated mathematical analysis                      0.000000   0.000000  ...   \n",
              "perform speech recognition python                   0.000000   0.000000  ...   \n",
              "beyond semesters                                    0.000000   0.000000  ...   \n",
              "improve classification pages incorporating mult...  0.000000   0.000000  ...   \n",
              "time series forecasting thymeboost                  0.000000   0.000000  ...   \n",
              "chapter chose data science                          0.000000   0.000000  ...   \n",
              "training neural networks                            0.000000   0.000000  ...   \n",
              "time series forecasting thymeboost                  0.000000   0.000000  ...   \n",
              "improve classification pages incorporating mult...  0.000000   0.000000  ...   \n",
              "cute features catboost                              0.000000   0.000000  ...   \n",
              "variance inflation factor vif relationship mult...  0.000000   0.000000  ...   \n",
              "beyond semesters                                    0.000000   0.000000  ...   \n",
              "efficient digital transformation particle swarm...  0.000000   0.000000  ...   \n",
              "measure asymmetry                                   0.000000   1.510212  ...   \n",
              "linear regression quick cover tutorial              0.000000   0.000000  ...   \n",
              "correlation vs covariance easy way                  0.000000   0.000000  ...   \n",
              "recommender system harming us                       0.000000   0.000000  ...   \n",
              "line python code speed ai                           0.000000   0.000000  ...   \n",
              "serious data science job must know things           0.000000   0.000000  ...   \n",
              "recommender system machine learning statistics      0.000000   0.000000  ...   \n",
              "bias detection mitigation ibm autoai                0.000000   0.000000  ...   \n",
              "data engineering create dataset                     0.000000   0.000000  ...   \n",
              "graph neural networks generalizable models neur...  0.000000   0.000000  ...   \n",
              "fastest way deploying machine learning models       0.000000   0.000000  ...   \n",
              "novel approach integrate speech recognition aut...  0.000000   0.000000  ...   \n",
              "lessons learned teaching machine learning earth...  0.000000   0.000000  ...   \n",
              "vision transformer galaxy morphology classifica...  0.000000   0.000000  ...   \n",
              "exploring methods deep reinforcement learning n...  0.000000   0.000000  ...   \n",
              "essential tips solve data science projects          0.000000   0.000000  ...   \n",
              "data science interview questions friends got as...  0.335603   0.000000  ...   \n",
              "understanding uber generative teaching networks     0.000000   0.000000  ...   \n",
              "achieve efficient training                          0.000000   0.000000  ...   \n",
              "parallelization large batch size improve perfor...  0.000000   0.000000  ...   \n",
              "need know inner workings models                     0.000000   0.000000  ...   \n",
              "let build simple object classification task         0.000000   0.000000  ...   \n",
              "\n",
              "                                                        uber  understanding  \\\n",
              "machine learning                                    0.000000       0.000000   \n",
              "five advanced plots python matplotlib               0.000000       0.000000   \n",
              "make computer talk python                           0.000000       0.000000   \n",
              "anomaly detection servo drives                      0.000000       0.000000   \n",
              "key takeaways kaggle recent time series competi...  0.000000       0.000000   \n",
              "animated mathematical analysis                      0.000000       0.000000   \n",
              "perform speech recognition python                   0.000000       0.000000   \n",
              "beyond semesters                                    0.000000       0.000000   \n",
              "improve classification pages incorporating mult...  0.000000       0.000000   \n",
              "time series forecasting thymeboost                  0.000000       0.000000   \n",
              "chapter chose data science                          0.000000       0.000000   \n",
              "training neural networks                            0.000000       0.000000   \n",
              "time series forecasting thymeboost                  0.000000       0.000000   \n",
              "improve classification pages incorporating mult...  0.000000       0.000000   \n",
              "cute features catboost                              0.000000       0.000000   \n",
              "variance inflation factor vif relationship mult...  0.000000       0.000000   \n",
              "beyond semesters                                    0.000000       0.000000   \n",
              "efficient digital transformation particle swarm...  0.000000       0.000000   \n",
              "measure asymmetry                                   0.000000       0.000000   \n",
              "linear regression quick cover tutorial              0.000000       0.000000   \n",
              "correlation vs covariance easy way                  0.000000       0.000000   \n",
              "recommender system harming us                       0.000000       0.000000   \n",
              "line python code speed ai                           0.000000       0.000000   \n",
              "serious data science job must know things           0.000000       0.000000   \n",
              "recommender system machine learning statistics      0.000000       0.000000   \n",
              "bias detection mitigation ibm autoai                0.000000       0.000000   \n",
              "data engineering create dataset                     0.000000       0.000000   \n",
              "graph neural networks generalizable models neur...  0.000000       0.000000   \n",
              "fastest way deploying machine learning models       0.000000       0.000000   \n",
              "novel approach integrate speech recognition aut...  0.000000       0.000000   \n",
              "lessons learned teaching machine learning earth...  0.000000       0.000000   \n",
              "vision transformer galaxy morphology classifica...  0.000000       0.000000   \n",
              "exploring methods deep reinforcement learning n...  0.000000       0.000000   \n",
              "essential tips solve data science projects          0.000000       0.000000   \n",
              "data science interview questions friends got as...  0.000000       0.000000   \n",
              "understanding uber generative teaching networks     0.604085       0.604085   \n",
              "achieve efficient training                          0.000000       0.000000   \n",
              "parallelization large batch size improve perfor...  0.000000       0.000000   \n",
              "need know inner workings models                     0.000000       0.000000   \n",
              "let build simple object classification task         0.000000       0.000000   \n",
              "\n",
              "                                                          us  variance  \\\n",
              "machine learning                                    0.000000  0.000000   \n",
              "five advanced plots python matplotlib               0.000000  0.000000   \n",
              "make computer talk python                           0.000000  0.000000   \n",
              "anomaly detection servo drives                      0.000000  0.000000   \n",
              "key takeaways kaggle recent time series competi...  0.000000  0.000000   \n",
              "animated mathematical analysis                      0.000000  0.000000   \n",
              "perform speech recognition python                   0.000000  0.000000   \n",
              "beyond semesters                                    0.000000  0.000000   \n",
              "improve classification pages incorporating mult...  0.000000  0.000000   \n",
              "time series forecasting thymeboost                  0.000000  0.000000   \n",
              "chapter chose data science                          0.000000  0.000000   \n",
              "training neural networks                            0.000000  0.000000   \n",
              "time series forecasting thymeboost                  0.000000  0.000000   \n",
              "improve classification pages incorporating mult...  0.000000  0.000000   \n",
              "cute features catboost                              0.000000  0.000000   \n",
              "variance inflation factor vif relationship mult...  0.000000  0.431489   \n",
              "beyond semesters                                    0.000000  0.000000   \n",
              "efficient digital transformation particle swarm...  0.000000  0.000000   \n",
              "measure asymmetry                                   0.000000  0.000000   \n",
              "linear regression quick cover tutorial              0.000000  0.000000   \n",
              "correlation vs covariance easy way                  0.000000  0.000000   \n",
              "recommender system harming us                       0.755106  0.000000   \n",
              "line python code speed ai                           0.000000  0.000000   \n",
              "serious data science job must know things           0.000000  0.000000   \n",
              "recommender system machine learning statistics      0.000000  0.000000   \n",
              "bias detection mitigation ibm autoai                0.000000  0.000000   \n",
              "data engineering create dataset                     0.000000  0.000000   \n",
              "graph neural networks generalizable models neur...  0.000000  0.000000   \n",
              "fastest way deploying machine learning models       0.000000  0.000000   \n",
              "novel approach integrate speech recognition aut...  0.000000  0.000000   \n",
              "lessons learned teaching machine learning earth...  0.000000  0.000000   \n",
              "vision transformer galaxy morphology classifica...  0.000000  0.000000   \n",
              "exploring methods deep reinforcement learning n...  0.000000  0.000000   \n",
              "essential tips solve data science projects          0.000000  0.000000   \n",
              "data science interview questions friends got as...  0.000000  0.000000   \n",
              "understanding uber generative teaching networks     0.000000  0.000000   \n",
              "achieve efficient training                          0.000000  0.000000   \n",
              "parallelization large batch size improve perfor...  0.000000  0.000000   \n",
              "need know inner workings models                     0.000000  0.000000   \n",
              "let build simple object classification task         0.000000  0.000000   \n",
              "\n",
              "                                                    ventilator       vif  \\\n",
              "machine learning                                      0.000000  0.000000   \n",
              "five advanced plots python matplotlib                 0.000000  0.000000   \n",
              "make computer talk python                             0.000000  0.000000   \n",
              "anomaly detection servo drives                        0.000000  0.000000   \n",
              "key takeaways kaggle recent time series competi...    0.302042  0.000000   \n",
              "animated mathematical analysis                        0.000000  0.000000   \n",
              "perform speech recognition python                     0.000000  0.000000   \n",
              "beyond semesters                                      0.000000  0.000000   \n",
              "improve classification pages incorporating mult...    0.000000  0.000000   \n",
              "time series forecasting thymeboost                    0.000000  0.000000   \n",
              "chapter chose data science                            0.000000  0.000000   \n",
              "training neural networks                              0.000000  0.000000   \n",
              "time series forecasting thymeboost                    0.000000  0.000000   \n",
              "improve classification pages incorporating mult...    0.000000  0.000000   \n",
              "cute features catboost                                0.000000  0.000000   \n",
              "variance inflation factor vif relationship mult...    0.000000  0.431489   \n",
              "beyond semesters                                      0.000000  0.000000   \n",
              "efficient digital transformation particle swarm...    0.000000  0.000000   \n",
              "measure asymmetry                                     0.000000  0.000000   \n",
              "linear regression quick cover tutorial                0.000000  0.000000   \n",
              "correlation vs covariance easy way                    0.000000  0.000000   \n",
              "recommender system harming us                         0.000000  0.000000   \n",
              "line python code speed ai                             0.000000  0.000000   \n",
              "serious data science job must know things             0.000000  0.000000   \n",
              "recommender system machine learning statistics        0.000000  0.000000   \n",
              "bias detection mitigation ibm autoai                  0.000000  0.000000   \n",
              "data engineering create dataset                       0.000000  0.000000   \n",
              "graph neural networks generalizable models neur...    0.000000  0.000000   \n",
              "fastest way deploying machine learning models         0.000000  0.000000   \n",
              "novel approach integrate speech recognition aut...    0.000000  0.000000   \n",
              "lessons learned teaching machine learning earth...    0.000000  0.000000   \n",
              "vision transformer galaxy morphology classifica...    0.000000  0.000000   \n",
              "exploring methods deep reinforcement learning n...    0.000000  0.000000   \n",
              "essential tips solve data science projects            0.000000  0.000000   \n",
              "data science interview questions friends got as...    0.000000  0.000000   \n",
              "understanding uber generative teaching networks       0.000000  0.000000   \n",
              "achieve efficient training                            0.000000  0.000000   \n",
              "parallelization large batch size improve perfor...    0.000000  0.000000   \n",
              "need know inner workings models                       0.000000  0.000000   \n",
              "let build simple object classification task           0.000000  0.000000   \n",
              "\n",
              "                                                      vision        vs  \\\n",
              "machine learning                                    0.000000  0.000000   \n",
              "five advanced plots python matplotlib               0.000000  0.000000   \n",
              "make computer talk python                           0.000000  0.000000   \n",
              "anomaly detection servo drives                      0.000000  0.000000   \n",
              "key takeaways kaggle recent time series competi...  0.000000  0.000000   \n",
              "animated mathematical analysis                      0.000000  0.000000   \n",
              "perform speech recognition python                   0.000000  0.000000   \n",
              "beyond semesters                                    0.000000  0.000000   \n",
              "improve classification pages incorporating mult...  0.000000  0.000000   \n",
              "time series forecasting thymeboost                  0.000000  0.000000   \n",
              "chapter chose data science                          0.000000  0.000000   \n",
              "training neural networks                            0.000000  0.000000   \n",
              "time series forecasting thymeboost                  0.000000  0.000000   \n",
              "improve classification pages incorporating mult...  0.000000  0.000000   \n",
              "cute features catboost                              0.000000  0.000000   \n",
              "variance inflation factor vif relationship mult...  0.000000  0.000000   \n",
              "beyond semesters                                    0.000000  0.000000   \n",
              "efficient digital transformation particle swarm...  0.000000  0.000000   \n",
              "measure asymmetry                                   0.000000  0.000000   \n",
              "linear regression quick cover tutorial              0.000000  0.000000   \n",
              "correlation vs covariance easy way                  0.000000  0.604085   \n",
              "recommender system harming us                       0.000000  0.000000   \n",
              "line python code speed ai                           0.000000  0.000000   \n",
              "serious data science job must know things           0.000000  0.000000   \n",
              "recommender system machine learning statistics      0.000000  0.000000   \n",
              "bias detection mitigation ibm autoai                0.000000  0.000000   \n",
              "data engineering create dataset                     0.000000  0.000000   \n",
              "graph neural networks generalizable models neur...  0.000000  0.000000   \n",
              "fastest way deploying machine learning models       0.000000  0.000000   \n",
              "novel approach integrate speech recognition aut...  0.000000  0.000000   \n",
              "lessons learned teaching machine learning earth...  0.000000  0.000000   \n",
              "vision transformer galaxy morphology classifica...  0.604085  0.000000   \n",
              "exploring methods deep reinforcement learning n...  0.000000  0.000000   \n",
              "essential tips solve data science projects          0.000000  0.000000   \n",
              "data science interview questions friends got as...  0.000000  0.000000   \n",
              "understanding uber generative teaching networks     0.000000  0.000000   \n",
              "achieve efficient training                          0.000000  0.000000   \n",
              "parallelization large batch size improve perfor...  0.000000  0.000000   \n",
              "need know inner workings models                     0.000000  0.000000   \n",
              "let build simple object classification task         0.000000  0.000000   \n",
              "\n",
              "                                                         way  workings  \n",
              "machine learning                                    0.000000  0.000000  \n",
              "five advanced plots python matplotlib               0.000000  0.000000  \n",
              "make computer talk python                           0.000000  0.000000  \n",
              "anomaly detection servo drives                      0.000000  0.000000  \n",
              "key takeaways kaggle recent time series competi...  0.000000  0.000000  \n",
              "animated mathematical analysis                      0.000000  0.000000  \n",
              "perform speech recognition python                   0.000000  0.000000  \n",
              "beyond semesters                                    0.000000  0.000000  \n",
              "improve classification pages incorporating mult...  0.000000  0.000000  \n",
              "time series forecasting thymeboost                  0.000000  0.000000  \n",
              "chapter chose data science                          0.000000  0.000000  \n",
              "training neural networks                            0.000000  0.000000  \n",
              "time series forecasting thymeboost                  0.000000  0.000000  \n",
              "improve classification pages incorporating mult...  0.000000  0.000000  \n",
              "cute features catboost                              0.000000  0.000000  \n",
              "variance inflation factor vif relationship mult...  0.000000  0.000000  \n",
              "beyond semesters                                    0.000000  0.000000  \n",
              "efficient digital transformation particle swarm...  0.000000  0.000000  \n",
              "measure asymmetry                                   0.000000  0.000000  \n",
              "linear regression quick cover tutorial              0.000000  0.000000  \n",
              "correlation vs covariance easy way                  0.522992  0.000000  \n",
              "recommender system harming us                       0.000000  0.000000  \n",
              "line python code speed ai                           0.000000  0.000000  \n",
              "serious data science job must know things           0.000000  0.000000  \n",
              "recommender system machine learning statistics      0.000000  0.000000  \n",
              "bias detection mitigation ibm autoai                0.000000  0.000000  \n",
              "data engineering create dataset                     0.000000  0.000000  \n",
              "graph neural networks generalizable models neur...  0.000000  0.000000  \n",
              "fastest way deploying machine learning models       0.435827  0.000000  \n",
              "novel approach integrate speech recognition aut...  0.000000  0.000000  \n",
              "lessons learned teaching machine learning earth...  0.000000  0.000000  \n",
              "vision transformer galaxy morphology classifica...  0.000000  0.000000  \n",
              "exploring methods deep reinforcement learning n...  0.000000  0.000000  \n",
              "essential tips solve data science projects          0.000000  0.000000  \n",
              "data science interview questions friends got as...  0.000000  0.000000  \n",
              "understanding uber generative teaching networks     0.000000  0.000000  \n",
              "achieve efficient training                          0.000000  0.000000  \n",
              "parallelization large batch size improve perfor...  0.000000  0.000000  \n",
              "need know inner workings models                     0.000000  0.604085  \n",
              "let build simple object classification task         0.000000  0.000000  \n",
              "\n",
              "[40 rows x 151 columns]"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def compute_tf(doc):\n",
        "    \"\"\"\n",
        "    Compute Term Frequency (TF) for a single document.\n",
        "    \"\"\"\n",
        "    words = doc.split()\n",
        "    word_count = len(words)\n",
        "    tf = {word: words.count(word) / word_count for word in words}\n",
        "    return tf\n",
        "\n",
        "def compute_idf(corpus):\n",
        "    \"\"\"\n",
        "    Compute Inverse Document Frequency (IDF) for all terms in the corpus.\n",
        "    \"\"\"\n",
        "    num_docs = len(corpus)\n",
        "    idf = {}\n",
        "    all_words = set(word for doc in corpus for word in doc.split())\n",
        "    for word in all_words:\n",
        "        containing_docs = sum(1 for doc in corpus if word in doc.split())\n",
        "        idf[word] = np.log((num_docs + 1) / (containing_docs + 1))  # Add 1 to avoid division by zero\n",
        "    return idf\n",
        "\n",
        "\n",
        "def compute_tfidf(corpus):\n",
        "    \"\"\"\n",
        "    Compute TF-IDF for the entire corpus.\n",
        "    \"\"\"\n",
        "    idf = compute_idf(corpus)\n",
        "    tfidf = []\n",
        "    for doc in corpus:\n",
        "        tf = compute_tf(doc)\n",
        "        tfidf.append({word: tf[word] * idf[word] for word in tf})\n",
        "    return tfidf\n",
        "\n",
        "\n",
        "# processed_documents = [preprocess_doc(doc, tokenizer=wordpunct_tokenize,stemmer=lancaster) for doc in documents]\n",
        "processed_documents = [preprocess_doc(doc) for doc in documents]\n",
        "# Compute TF-IDF\n",
        "tfidf = compute_tfidf(processed_documents)\n",
        "\n",
        "# Convert to DataFrame\n",
        "all_words = set(word for doc in processed_documents for word in doc.split())\n",
        "tfidf_matrix = pd.DataFrame([{word: doc_tfidf.get(word, 0) for word in all_words} for doc_tfidf in tfidf], index=processed_documents).sort_index(axis=1)\n",
        "\n",
        "print(\"Custom TF-IDF Matrix:\")\n",
        "tfidf_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce4c97be",
      "metadata": {
        "id": "ce4c97be"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "be692110",
      "metadata": {
        "id": "be692110"
      },
      "source": [
        "## Task 4\n",
        "Create a search engine based on TFIDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "id": "6b884af5",
      "metadata": {
        "id": "6b884af5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranked Results:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\mmart\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\spatial\\distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  dist = 1.0 - uv / math.sqrt(uu * vv)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "machine learning                                                                     NaN\n",
              "five advanced plots python matplotlib                                                NaN\n",
              "make computer talk python                                                            NaN\n",
              "anomaly detection servo drives                                                       NaN\n",
              "key takeaways kaggle recent time series competition ventilator pressure prediction   NaN\n",
              "animated mathematical analysis                                                       NaN\n",
              "perform speech recognition python                                                    NaN\n",
              "beyond semesters                                                                     NaN\n",
              "improve classification pages incorporating multiple modalities                       NaN\n",
              "time series forecasting thymeboost                                                   NaN\n",
              "chapter chose data science                                                           NaN\n",
              "training neural networks                                                             NaN\n",
              "time series forecasting thymeboost                                                   NaN\n",
              "improve classification pages incorporating multiple modalities                       NaN\n",
              "cute features catboost                                                               NaN\n",
              "variance inflation factor vif relationship multicollinearity nbsp                    NaN\n",
              "beyond semesters                                                                     NaN\n",
              "efficient digital transformation particle swarm optimiser                            NaN\n",
              "measure asymmetry                                                                    NaN\n",
              "linear regression quick cover tutorial                                               NaN\n",
              "correlation vs covariance easy way                                                   NaN\n",
              "recommender system harming us                                                        NaN\n",
              "line python code speed ai                                                            NaN\n",
              "serious data science job must know things                                            NaN\n",
              "recommender system machine learning statistics                                       NaN\n",
              "bias detection mitigation ibm autoai                                                 NaN\n",
              "data engineering create dataset                                                      NaN\n",
              "graph neural networks generalizable models neuroscience                              NaN\n",
              "fastest way deploying machine learning models                                        NaN\n",
              "novel approach integrate speech recognition authentication systems                   NaN\n",
              "lessons learned teaching machine learning earth observation techniques               NaN\n",
              "vision transformer galaxy morphology classification                                  NaN\n",
              "exploring methods deep reinforcement learning nlp applications                       NaN\n",
              "essential tips solve data science projects                                           NaN\n",
              "data science interview questions friends got asked recently iii                      NaN\n",
              "understanding uber generative teaching networks                                      NaN\n",
              "achieve efficient training                                                           NaN\n",
              "parallelization large batch size improve performance deep neural networks            NaN\n",
              "need know inner workings models                                                      NaN\n",
              "let build simple object classification task                                          NaN\n",
              "dtype: float64"
            ]
          },
          "execution_count": 144,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def search(query, df):\n",
        "    processed_query = preprocess_doc(query)\n",
        "    query_tfidf = compute_tfidf([processed_query])[0]\n",
        "    query_vector = np.array([query_tfidf.get(term, 0) for term in df.columns])\n",
        "    similarity_scores = [1 - cosine(doc_vector, query_vector) for doc_vector in df.values]    \n",
        "    ranked_results = pd.Series(similarity_scores, index=df.index).sort_values(ascending=False)\n",
        "    return ranked_results\n",
        "    \n",
        "query = \"how to machine learning\"\n",
        "results = search(query, tfidf_matrix)\n",
        "print(\"Ranked Results:\")\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "id": "e2d715e7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "def search(query, df):\n",
        "    \"\"\"\n",
        "    Perform a search using TF-IDF and cosine similarity.\n",
        "\n",
        "    Parameters:\n",
        "    - query: str, the user's search query.\n",
        "    - df: pd.DataFrame, the TF-IDF matrix with terms as columns and documents as rows.\n",
        "\n",
        "    Returns:\n",
        "    - pd.Series: Ranked documents with their similarity scores.\n",
        "    \"\"\"\n",
        "    # Preprocess the query\n",
        "    processed_query = preprocess_doc(query)\n",
        "    \n",
        "    # Compute TF-IDF for the query\n",
        "    query_tfidf = compute_tfidf([processed_query])[0]\n",
        "    \n",
        "    # Align the query vector with the TF-IDF matrix columns\n",
        "    query_vector = np.array([query_tfidf.get(term, 0) for term in df.columns])\n",
        "    print(query_vector)\n",
        "    \n",
        "    missing_terms = [term for term in processed_query.split() if term not in df.columns]\n",
        "    if missing_terms:\n",
        "        print(f\"Warning: These query terms are not in the TF-IDF vocabulary: {missing_terms}\")\n",
        "\n",
        "    # Ensure the query vector is non-zero\n",
        "    if np.linalg.norm(query_vector) == 0:\n",
        "        return pd.Series([0] * len(df), index=df.index).sort_values(ascending=False)\n",
        "    \n",
        "    # Compute cosine similarity, handling zero document vectors\n",
        "    similarity_scores = [\n",
        "        1 - cosine(doc_vector, query_vector) if np.linalg.norm(doc_vector) != 0 else 0\n",
        "        for doc_vector in df.values\n",
        "    ]\n",
        "    \n",
        "    # Rank documents by similarity\n",
        "    ranked_results = pd.Series(similarity_scores, index=df.index).sort_values(ascending=False)\n",
        "    return ranked_results\n",
        "\n",
        "\n",
        "query = \"how to machine learning\"\n",
        "results = search(query, tfidf_matrix)\n",
        "# print(\"Ranked Results:\")\n",
        "# results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "id": "640e6dc0",
      "metadata": {},
      "outputs": [],
      "source": [
        "def search(query, df):\n",
        "    \"\"\"\n",
        "    Perform a search using TF-IDF and cosine similarity.\n",
        "\n",
        "    Parameters:\n",
        "    - query: str, the user's search query.\n",
        "    - df: pd.DataFrame, the TF-IDF matrix with terms as columns and documents as rows.\n",
        "\n",
        "    Returns:\n",
        "    - pd.Series: Ranked documents with their similarity scores.\n",
        "    \"\"\"\n",
        "    # Preprocess the query\n",
        "    processed_query = preprocess_doc(query)\n",
        "    print(f\"Processed Query: {processed_query}\")  # Debugging\n",
        "    \n",
        "    # Compute TF-IDF for the query\n",
        "    query_tfidf = compute_tfidf([processed_query])[0]\n",
        "    print(f\"Query TF-IDF: {query_tfidf}\")  # Debugging\n",
        "    \n",
        "    # Align the query vector with the TF-IDF matrix columns\n",
        "    query_vector = np.array([query_tfidf.get(term, 0) for term in df.columns])\n",
        "    print(f\"Query Vector: {query_vector}\")  # Debugging\n",
        "    \n",
        "    # Check for missing terms in the vocabulary\n",
        "    missing_terms = [term for term in processed_query.split() if term not in df.columns]\n",
        "    if missing_terms:\n",
        "        print(f\"Warning: These query terms are not in the TF-IDF vocabulary: {missing_terms}\")\n",
        "    \n",
        "    # Ensure the query vector is non-zero\n",
        "    if np.linalg.norm(query_vector) == 0:\n",
        "        print(\"Warning: Query vector is all zeros.\")\n",
        "        return pd.Series([0] * len(df), index=df.index).sort_values(ascending=False)\n",
        "    \n",
        "    # Compute cosine similarity\n",
        "    similarity_scores = [\n",
        "        1 - cosine(doc_vector, query_vector) if np.linalg.norm(doc_vector) != 0 else 0\n",
        "        for doc_vector in df.values\n",
        "    ]\n",
        "    \n",
        "    # Rank documents by similarity\n",
        "    ranked_results = pd.Series(similarity_scores, index=df.index).sort_values(ascending=False)\n",
        "    return ranked_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "id": "973207bf",
      "metadata": {
        "id": "973207bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed Query: machine learning\n",
            "Query TF-IDF: {'machine': 0.0, 'learning': 0.0}\n",
            "Query Vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0.]\n",
            "Warning: Query vector is all zeros.\n",
            "Ranked Results:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "machine learning                                                                      0\n",
              "five advanced plots python matplotlib                                                 0\n",
              "line python code speed ai                                                             0\n",
              "serious data science job must know things                                             0\n",
              "recommender system machine learning statistics                                        0\n",
              "bias detection mitigation ibm autoai                                                  0\n",
              "data engineering create dataset                                                       0\n",
              "graph neural networks generalizable models neuroscience                               0\n",
              "fastest way deploying machine learning models                                         0\n",
              "novel approach integrate speech recognition authentication systems                    0\n",
              "lessons learned teaching machine learning earth observation techniques                0\n",
              "vision transformer galaxy morphology classification                                   0\n",
              "exploring methods deep reinforcement learning nlp applications                        0\n",
              "essential tips solve data science projects                                            0\n",
              "data science interview questions friends got asked recently iii                       0\n",
              "understanding uber generative teaching networks                                       0\n",
              "achieve efficient training                                                            0\n",
              "parallelization large batch size improve performance deep neural networks             0\n",
              "need know inner workings models                                                       0\n",
              "recommender system harming us                                                         0\n",
              "correlation vs covariance easy way                                                    0\n",
              "linear regression quick cover tutorial                                                0\n",
              "time series forecasting thymeboost                                                    0\n",
              "make computer talk python                                                             0\n",
              "anomaly detection servo drives                                                        0\n",
              "key takeaways kaggle recent time series competition ventilator pressure prediction    0\n",
              "animated mathematical analysis                                                        0\n",
              "perform speech recognition python                                                     0\n",
              "beyond semesters                                                                      0\n",
              "improve classification pages incorporating multiple modalities                        0\n",
              "chapter chose data science                                                            0\n",
              "measure asymmetry                                                                     0\n",
              "training neural networks                                                              0\n",
              "time series forecasting thymeboost                                                    0\n",
              "improve classification pages incorporating multiple modalities                        0\n",
              "cute features catboost                                                                0\n",
              "variance inflation factor vif relationship multicollinearity nbsp                     0\n",
              "beyond semesters                                                                      0\n",
              "efficient digital transformation particle swarm optimiser                             0\n",
              "let build simple object classification task                                           0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 147,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"how to machine learning\"\n",
        "results = search(query, tfidf_matrix)\n",
        "print(\"Ranked Results:\")\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b5e9c4a",
      "metadata": {
        "id": "3b5e9c4a"
      },
      "source": [
        "## Task 5\n",
        "Create a search engine based on history containing more than one document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "id": "4ff24faf",
      "metadata": {
        "id": "4ff24faf"
      },
      "outputs": [],
      "source": [
        "def search(history, df):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8846314",
      "metadata": {
        "id": "b8846314"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e59dbf7",
      "metadata": {
        "id": "9e59dbf7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "ab0675e6",
      "metadata": {
        "id": "ab0675e6"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
