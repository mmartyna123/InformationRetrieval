{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e1f3d86e",
      "metadata": {
        "id": "e1f3d86e"
      },
      "source": [
        "In this class, we will talk about model explainability but more in the context of data explainability or root cause analysis. In many cases building a very good machine learning model is not an ultimate goal. What is really wanted is the data understanding. A factory wants to know why the product is plagued with a defect, not to predict afterward if there is a defect or not. A football team wants to know which position is the best for scoring a goal, not what's the probability of scoring from a given position. And even when they want a prediction they would love to see the justification to trust the model. Often a nice plot is worth more than sophisticated machine-learning approaches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cf435ee",
      "metadata": {
        "id": "0cf435ee"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import dalex as dx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.datasets import load_wine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac5edb05",
      "metadata": {
        "id": "ac5edb05"
      },
      "outputs": [],
      "source": [
        "data = load_wine()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18835b4c",
      "metadata": {
        "id": "18835b4c"
      },
      "outputs": [],
      "source": [
        "data\n",
        "df = pd.DataFrame(data['data'], columns=data['feature_names'])\n",
        "y = data['target']\n",
        "df['target'] = y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "521043b8",
      "metadata": {
        "id": "521043b8"
      },
      "source": [
        "You should already be familiar with many data visualization techniques so we will not train it now. I just want to share a less popular type of data analysis. Usually plotting the target against any feature is not helpful but after some modification, we might be able to see some patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eae45f14",
      "metadata": {
        "id": "eae45f14"
      },
      "outputs": [],
      "source": [
        "plt.plot(df.flavanoids, y, 'bo')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21d4d36d",
      "metadata": {
        "id": "21d4d36d"
      },
      "source": [
        "For each value, we can plot the average target for data:\n",
        " - below that value\n",
        " - above that value\n",
        " - around that value\n",
        "\n",
        "Please note that for the line \"above that value\" the more left we go the higher fraction of data is covered. The same with the \"below that value\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2787ded9",
      "metadata": {
        "scrolled": true,
        "id": "2787ded9"
      },
      "outputs": [],
      "source": [
        "for col in df.columns.drop('target'):\n",
        "    tmp = df.sort_values(col)\n",
        "    plt.title(col)\n",
        "    plt.plot(tmp[col], tmp[col].apply(lambda x: tmp[tmp[col] <= x].target.mean()), label=\"<=\")\n",
        "    plt.plot(tmp[col], tmp[col].apply(lambda x: tmp[tmp[col] >= x].target.mean()), label=\">=\")\n",
        "    plt.plot(tmp[col], np.convolve(np.ones(20)/20, tmp.target, mode='same'), label= \"~=~\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bffc8a5",
      "metadata": {
        "id": "4bffc8a5"
      },
      "source": [
        "Ok, let's just train a model. We are not interested in top performance right now so we will skip hyperparameter optimization. Also, we want to find the pattern in the data we have, so we don't split the data into validation and test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0544ef6c",
      "metadata": {
        "id": "0544ef6c"
      },
      "outputs": [],
      "source": [
        "model = RandomForestRegressor()\n",
        "x = df.drop('target', axis=1)\n",
        "y = df.target\n",
        "model.fit(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db2868fd",
      "metadata": {
        "id": "db2868fd"
      },
      "outputs": [],
      "source": [
        "plt.plot(df.target, model.predict(x), 'bo')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "564d4ab7",
      "metadata": {
        "id": "564d4ab7"
      },
      "source": [
        "Dalex is a python package for model explainability. We will use some of its functions to understand the data and the model better. First, we need to create an explainer model. Since we are not interested in checking the model performance but the relation between the data and the target we will use the whole dataset here. In the first case, we might want to use the testing set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4522325a",
      "metadata": {
        "id": "4522325a"
      },
      "outputs": [],
      "source": [
        "exp = dx.Explainer(model, x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0296fb6",
      "metadata": {
        "id": "f0296fb6"
      },
      "outputs": [],
      "source": [
        "fi = exp.model_parts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd7d248a",
      "metadata": {
        "id": "cd7d248a"
      },
      "source": [
        "The first step will be feature importance. It's a basic analysis where we calculate the global impact of a feature. The idea in dalex default approach is to measure how much the model performance is worsening after removing this feature. Of course, it would require retraining the model, the optimal set of hyperparameters might be different and it might affect the results. To avoid these problems we do not retrain the model. Instead, we simulate its removal by assigning random values to it. To make it more realistic the values are not completely random, we just shuffle this column in a dataframe, do the prediction, check performance and repeat these steps multiple times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09f500ae",
      "metadata": {
        "id": "09f500ae"
      },
      "outputs": [],
      "source": [
        "fi.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7f9535a",
      "metadata": {
        "id": "b7f9535a"
      },
      "source": [
        "Another useful tool is a partial dependency plot. For a given feature we observe what's the average output of our model for different values of this feature. For each considered value we set this value for each row in our dataframe and calculate an average prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a20223d",
      "metadata": {
        "scrolled": false,
        "id": "3a20223d"
      },
      "outputs": [],
      "source": [
        "exp.model_profile().plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94a61afa",
      "metadata": {
        "id": "94a61afa"
      },
      "source": [
        "\n",
        "We can also create similar plots for single rows. Here for each column, we present what would be the output from the model assuming we keep all remaining values and change the value of this one selected feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b43ed2d2",
      "metadata": {
        "scrolled": false,
        "id": "b43ed2d2"
      },
      "outputs": [],
      "source": [
        "exp.predict_profile(x.iloc[[15,80]]).plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f7ef147",
      "metadata": {
        "id": "1f7ef147"
      },
      "source": [
        "SHAP values are equivalents of Shapley values for the predictive models. It estimates the effect of a particular value of a particular feature for a prediction of a considered row. It's also done by replacing this value with proper sampling and replacing this value and measuring the effect on the prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e417ef7",
      "metadata": {
        "id": "0e417ef7"
      },
      "outputs": [],
      "source": [
        "exp.predict_parts(x.iloc[15], type='shap').plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c8198c3",
      "metadata": {
        "id": "1c8198c3"
      },
      "outputs": [],
      "source": [
        "exp.predict_parts(x.iloc[15], type='shap').plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81dc4fb9",
      "metadata": {
        "id": "81dc4fb9"
      },
      "source": [
        "The result is based on sampling so the result for the same row can vary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9dd9aef",
      "metadata": {
        "id": "a9dd9aef"
      },
      "outputs": [],
      "source": [
        "exp.predict_parts(x.iloc[88], type='shap').plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daa295a9",
      "metadata": {
        "id": "daa295a9"
      },
      "outputs": [],
      "source": [
        "exp.predict_parts(x.iloc[88], type='shap').result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d3af9bd",
      "metadata": {
        "id": "4d3af9bd"
      },
      "source": [
        "**Task** For each class find the most representative examples and plot breakdown for them.\n",
        "\n",
        "Imagine we have a model classifying dogs and cats. Then a good example would be to show e.g. 3 breeds of dogs and the same with cats. Showing 5 golden retrievers although cute is not the best approach.\n",
        "\n",
        "There isn't a single best way how to approach this task. There are many good solutions. Think about what you want to achieve and then how to do it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "015c6cef",
      "metadata": {
        "id": "015c6cef"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85fa1740",
      "metadata": {
        "id": "85fa1740"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "d9736904",
      "metadata": {
        "id": "d9736904"
      },
      "source": [
        "There are other approaches that can be used for model explainability.\n",
        " - LIME - approximating model locally by a linear model\n",
        " - Anchor - approximating model locally by a rule-based model\n",
        " - Prototype - justifying a new prediction by showing a similar example from the data (a prototype)\n",
        " - Counterfactual Explanation - showing a similar exmaple from the dataset with a different prediction to show what must be changed to change the prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d7494d7",
      "metadata": {
        "id": "5d7494d7"
      },
      "source": [
        "# Task\n",
        "\n",
        "- take a dataset you want\n",
        "- perform an exploratory data analysis (data visualization)\n",
        "- create a sklearn pipeline for data preprocessing\n",
        "- add new features (one hot encoding for example)\n",
        "- add predictive model as the last step of the pipeline\n",
        "- prepare a report with model explainability\n",
        "\n",
        "Send it to gmiebs@cs.put.poznan.pl within 144 hours after the class is finished. Start the subject of the email with [IR]\n",
        "\n",
        "Assume your report will be read by a domain expert from the area of the data, in our case a wine expert, without any computer science / data science skills. It means the person will not get much from raw plots and diagrams. Everything has to be explained to be understood."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdabac1d",
      "metadata": {
        "id": "fdabac1d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}